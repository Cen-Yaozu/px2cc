{"version":3,"sources":["../../../node_modules/.pnpm/tsup@8.5.0_jiti@2.5.1_postcss@8.5.6_tsx@4.20.5_typescript@5.9.2_yaml@2.8.1/node_modules/tsup/assets/cjs_shims.js","../src/cognition/Cue.js","../src/cognition/FrequencyCue.js","../src/cognition/Network.js","../src/cognition/Mind.js","../src/cognition/Engram.js","../src/cognition/WeightContext.js","../src/cognition/Remember.js","../src/cognition/ActivationStrategy.js","../src/cognition/ActivationContext.js","../src/cognition/Recall.js","../src/cognition/Prime.js","../src/cognition/Memory.js","../src/cognition/WeightStrategy.js","../src/cognition/CognitionSystem.js","../src/cognition/index.js"],"sourcesContent":["// Shim globals in cjs bundle\n// There's a weird bug that esbuild will always inject importMetaUrl\n// if we export it as `const importMetaUrl = ... __filename ...`\n// But using a function will not cause this issue\n\nconst getImportMetaUrl = () =>\n  typeof document === 'undefined'\n    ? new URL(`file:${__filename}`).href\n    : (document.currentScript && document.currentScript.src) ||\n      new URL('main.js', document.baseURI).href\n\nexport const importMetaUrl = /* @__PURE__ */ getImportMetaUrl()\n","/**\n * Cue - 认知线索（记忆网络节点）\n * \n * ## 设计理念\n * \n * Cue是整个认知系统的原子单位，代表一个最小的认知概念。\n * 基于认知心理学的\"线索依赖记忆\"（Cue-dependent memory）理论：\n * - 记忆不是孤立存储的，而是通过线索（cue）相互连接\n * - 一个线索被激活时，会激活与其相连的其他线索\n * - 连接的强度（权重）决定了激活传播的概率和强度\n * \n * ## 为什么这样设计\n * \n * 1. **去中心化的连接管理**\n *    - 每个Cue管理自己的出边（connections），像神经元管理自己的突触\n *    - 避免了中央连接表的复杂性，符合生物神经网络的结构\n *    - 便于并行处理和局部更新\n * \n * 2. **极简的数据结构**\n *    - 只存储word（概念）和connections（连接）\n *    - 不存储原始内容，因为：\n *      a) 大模型本身就能理解word的语义\n *      b) 记忆本身就是模糊的、重构性的\n *      c) 节省存储空间，提高检索效率\n * \n * 3. **单向连接设计**\n *    - connections只记录出边，不记录入边\n *    - 原因：认知过程是有方向的（从A想到B，不一定从B想到A）\n *    - 简化了数据结构，避免了双向同步的复杂性\n * \n * ## 数据结构说明\n * \n * ```javascript\n * {\n *   word: \"认知\",                    // 概念本身\n *   connections: Map {               // 出边集合\n *     \"模型\" => 1234567890.5,       // 目标词 => 权重（时间戳*衰减因子）\n *     \"理解\" => 1234567880.3\n *   }\n * }\n * ```\n * \n * ## 权重的含义\n * \n * 权重不是简单的强度值，而是编码了多个维度的信息：\n * - 时间信息：通过时间戳基数体现新旧\n * - 位置信息：通过位置衰减体现序列中的重要性\n * - 网络信息：通过出度调整体现节点的hub特性\n * \n * @class Cue\n */\nclass Cue {\n  /**\n   * 创建一个新的Cue节点\n   * \n   * @param {string} word - 概念词，作为节点的唯一标识\n   * \n   * @example\n   * const cue = new Cue(\"认知\");\n   * cue.connections.set(\"模型\", 1234567890);\n   */\n  constructor(word) {\n    /**\n     * 概念词 - Cue的核心标识\n     * \n     * 设计考虑：\n     * - 使用词而不是ID，便于理解和调试\n     * - 词本身就携带语义信息，大模型可以直接理解\n     * - 支持任何语言的词汇（中文、英文、混合）\n     * \n     * @type {string}\n     */\n    this.word = word;\n    \n    /**\n     * 连接映射表 - 管理所有出边\n     * \n     * 数据结构：Map<targetWord, weight>\n     * - key: 目标Cue的word\n     * - value: 连接权重（number）\n     * \n     * 为什么用Map而不是Object：\n     * - Map的键可以是任何类型（虽然这里是string）\n     * - Map保持插入顺序（便于按时间顺序遍历）\n     * - Map有更好的性能（频繁增删改查）\n     * - Map有size属性（便于计算出度）\n     * \n     * @type {Map<string, number>}\n     */\n    this.connections = new Map();\n  }\n  \n  /**\n   * 获取节点的出度（连接到多少个其他节点）\n   * \n   * 出度的意义：\n   * - 高出度 = 枢纽节点（hub），概念发散性强\n   * - 低出度 = 专门节点，概念专一性强\n   * \n   * @returns {number} 出边数量\n   */\n  getOutDegree() {\n    return this.connections.size;\n  }\n  \n  /**\n   * 获取最强连接（权重最高的出边）\n   * \n   * 用途：\n   * - Prime时选择默认激活路径\n   * - Recall时决定主要扩散方向\n   * \n   * @returns {{word: string, weight: number}|null} 最强连接信息\n   */\n  getStrongestConnection() {\n    if (this.connections.size === 0) return null;\n    \n    let maxWeight = -Infinity;\n    let strongestWord = null;\n    \n    for (const [word, weight] of this.connections) {\n      if (weight > maxWeight) {\n        maxWeight = weight;\n        strongestWord = word;\n      }\n    }\n    \n    return { word: strongestWord, weight: maxWeight };\n  }\n  \n  /**\n   * 获取按权重排序的连接列表\n   * \n   * @param {number} limit - 返回前N个连接\n   * @returns {Array<{word: string, weight: number}>} 排序后的连接列表\n   */\n  getSortedConnections(limit = Infinity) {\n    return Array.from(this.connections.entries())\n      .map(([word, weight]) => ({ word, weight }))\n      .sort((a, b) => b.weight - a.weight)\n      .slice(0, limit);\n  }\n  \n  /**\n   * 序列化为JSON对象（用于持久化）\n   * \n   * @returns {Object} 可序列化的对象\n   */\n  toJSON() {\n    return {\n      word: this.word,\n      connections: Array.from(this.connections.entries()).map(([target, weight]) => ({\n        target,\n        weight\n      }))\n    };\n  }\n  \n  /**\n   * 从JSON对象恢复（用于加载）\n   * \n   * @param {Object} json - 序列化的对象\n   * @returns {Cue} 恢复的Cue实例\n   */\n  static fromJSON(json) {\n    const cue = new Cue(json.word);\n    if (json.connections) {\n      for (const conn of json.connections) {\n        cue.connections.set(conn.target, conn.weight);\n      }\n    }\n    return cue;\n  }\n}\n\nmodule.exports = Cue;","const Cue = require('./Cue');\nconst logger = require('@promptx/logger');\n\n/**\n * FrequencyCue - 带频率统计的认知线索\n * \n * ## 设计理念\n * \n * FrequencyCue继承自Cue，在保持Cue纯数据结构的基础上，\n * 添加了频率统计功能。这种设计遵循了开闭原则（OCP）：\n * - 对扩展开放：通过继承添加新功能\n * - 对修改关闭：不改变Cue的原有设计\n * \n * ## 为什么需要FrequencyCue\n * \n * 1. **使用强化原理**\n *    - 神经科学：\"neurons that fire together wire together\"\n *    - 频繁被激活的神经通路会得到强化\n *    - 模拟人类记忆的\"越用越强\"特性\n * \n * 2. **分离关注点**\n *    - Cue：纯粹的数据结构，表示概念和连接\n *    - FrequencyCue：添加统计信息，用于Network管理\n *    - 清晰的职责边界\n * \n * 3. **向后兼容**\n *    - FrequencyCue IS-A Cue，可以无缝替换\n *    - 所有使用Cue的地方都可以使用FrequencyCue\n *    - 不影响现有代码\n * \n * ## 频率的作用\n * \n * 在Softmax归一化时，频率作为偏置项：\n * ```\n * adjustedLogWeight = log(weight) + log(1 + frequency * α)\n * ```\n * \n * - 高频率的节点获得额外的激活概率\n * - 形成\"优先激活常用路径\"的模式\n * - 模拟工作记忆的激活模式\n * \n * @class FrequencyCue\n * @extends Cue\n */\nclass FrequencyCue extends Cue {\n  /**\n   * 创建一个带频率统计的Cue\n   * \n   * @param {string} word - 概念词\n   */\n  constructor(word) {\n    super(word);\n    \n    /**\n     * Recall频率 - 记录该节点被激活的次数\n     * \n     * 含义：\n     * - 每次被Recall激活时递增\n     * - 反映了概念在思考中的活跃度\n     * - 用于Softmax归一化时的频率偏置\n     * \n     * @type {number}\n     */\n    this.recallFrequency = 0;\n  }\n  \n  /**\n   * 增加recall频率\n   * \n   * 设计：\n   * - 简单递增，不设上限\n   * - 未来可以考虑添加衰减机制\n   * - 可以扩展为更复杂的统计（如时间窗口内的频率）\n   */\n  incrementFrequency() {\n    this.recallFrequency++;\n    logger.debug('[FrequencyCue] Frequency incremented', {\n      word: this.word,\n      newFrequency: this.recallFrequency\n    });\n  }\n  \n  /**\n   * 获取频率值\n   * \n   * @returns {number} 当前频率\n   */\n  getFrequency() {\n    return this.recallFrequency;\n  }\n  \n  /**\n   * 重置频率（用于测试或清理）\n   */\n  resetFrequency() {\n    this.recallFrequency = 0;\n    logger.debug('[FrequencyCue] Frequency reset', { word: this.word });\n  }\n  \n  /**\n   * 序列化为JSON（包含频率信息）\n   * \n   * @returns {Object} 包含频率的序列化对象\n   */\n  toJSON() {\n    return {\n      ...super.toJSON(),\n      recallFrequency: this.recallFrequency\n    };\n  }\n  \n  /**\n   * 从JSON恢复（包含频率信息）\n   * \n   * @param {Object} json - 序列化的对象\n   * @returns {FrequencyCue} 恢复的FrequencyCue实例\n   */\n  static fromJSON(json) {\n    const freqCue = new FrequencyCue(json.word);\n    \n    // 恢复连接\n    if (json.connections) {\n      for (const conn of json.connections) {\n        freqCue.connections.set(conn.target, conn.weight);\n      }\n    }\n    \n    // 恢复频率\n    freqCue.recallFrequency = json.recallFrequency || 0;\n    \n    return freqCue;\n  }\n  \n  /**\n   * 获取调试信息\n   * \n   * @returns {Object} 调试信息\n   */\n  getDebugInfo() {\n    return {\n      word: this.word,\n      outDegree: this.getOutDegree(),\n      recallFrequency: this.recallFrequency,\n      strongestConnection: this.getStrongestConnection()\n    };\n  }\n}\n\nmodule.exports = FrequencyCue;","const logger = require('@promptx/logger');\nconst fs = require('fs');\nconst path = require('path');\n\n/**\n * Network - 全局认知网络（所有 Cue 的容器）\n * \n * ## 设计理念\n * \n * Network是整个认知系统的基础设施，相当于生物大脑中的海马体（Hippocampus）。\n * 它不负责思考或推理，只负责存储和管理所有的记忆节点（Cue）。\n * \n * ## 为什么这样设计\n * \n * 1. **纯容器设计**\n *    - Network只是Cue的容器，不包含任何业务逻辑\n *    - 职责单一：存储、检索、持久化\n *    - 便于测试和维护\n * \n * 2. **去中心化架构**\n *    - 连接信息存储在Cue内部，Network不维护全局连接表\n *    - 优点：\n *      a) 避免了数据同步问题\n *      b) 支持局部更新，不需要全局锁\n *      c) 符合神经网络的生物学原理\n * \n * 3. **Map数据结构**\n *    - 使用Map而不是Object存储Cue\n *    - 原因：\n *      a) O(1)的查找性能\n *      b) 支持任何类型的键（虽然这里用string）\n *      c) 保持插入顺序（便于调试）\n *      d) 有明确的size属性\n * \n * ## 持久化设计\n * \n * 采用JSON格式持久化，结构如下：\n * ```json\n * {\n *   \"version\": \"1.0\",           // 版本号，便于未来升级\n *   \"timestamp\": 1234567890,     // 保存时间\n *   \"cues\": {                    // 所有Cue的集合\n *     \"认知\": {\n *       \"word\": \"认知\",\n *       \"connections\": [\n *         {\"target\": \"模型\", \"weight\": 1234567890}\n *       ]\n *     }\n *   }\n * }\n * ```\n * \n * ## 性能考虑\n * \n * - 单个Network预计存储10000+个Cue\n * - 每个Cue平均10-50个连接\n * - JSON文件大小：约1-10MB\n * - 加载时间：<100ms\n * \n * @class Network\n */\nclass Network {\n  constructor() {\n    /**\n     * Cue存储映射表\n     * \n     * 数据结构：Map<word, Cue>\n     * - key: 概念词（string）\n     * - value: Cue实例\n     * \n     * @type {Map<string, Cue>}\n     */\n    this.cues = new Map();\n    \n    logger.debug('[Network] Initialized empty network');\n  }\n  \n  /**\n   * 添加或获取Cue\n   * \n   * 如果Cue不存在则创建，存在则返回现有的。\n   * 这是一个幂等操作，多次调用结果相同。\n   * \n   * @param {string} word - 概念词\n   * @returns {FrequencyCue} FrequencyCue实例\n   */\n  getOrCreateCue(word) {\n    if (!this.cues.has(word)) {\n      const FrequencyCue = require('./FrequencyCue');\n      const cue = new FrequencyCue(word);\n      this.cues.set(word, cue);\n      logger.debug('[Network] Created new FrequencyCue', { word });\n    }\n    return this.cues.get(word);\n  }\n  \n  /**\n   * 获取Cue（不创建）\n   * \n   * @param {string} word - 概念词\n   * @returns {Cue|undefined} Cue实例或undefined\n   */\n  getCue(word) {\n    return this.cues.get(word);\n  }\n  \n  /**\n   * 检查Cue是否存在\n   * \n   * @param {string} word - 概念词\n   * @returns {boolean} 是否存在\n   */\n  hasCue(word) {\n    return this.cues.has(word);\n  }\n  \n  /**\n   * 获取网络规模\n   * \n   * @returns {number} Cue总数\n   */\n  size() {\n    return this.cues.size;\n  }\n  \n  /**\n   * 计算网络的入度信息\n   * \n   * 入度 = 有多少其他Cue指向这个Cue\n   * 这需要遍历整个网络，因为我们只存储出边。\n   * \n   * @returns {Map<string, number>} word => 入度\n   */\n  calculateInDegrees() {\n    const inDegrees = new Map();\n    \n    // 初始化所有Cue的入度为0\n    for (const word of this.cues.keys()) {\n      inDegrees.set(word, 0);\n    }\n    \n    // 遍历所有连接，累计入度\n    for (const [sourceWord, sourceCue] of this.cues) {\n      for (const targetWord of sourceCue.connections.keys()) {\n        const currentDegree = inDegrees.get(targetWord) || 0;\n        inDegrees.set(targetWord, currentDegree + 1);\n      }\n    }\n    \n    return inDegrees;\n  }\n  \n  /**\n   * 计算网络的入度权重（每个节点被指向的总权重）\n   * \n   * 用于Prime选择最重要的节点。\n   * \n   * @returns {Map<string, number>} word => 总入度权重\n   */\n  calculateInWeights() {\n    const inWeights = new Map();\n    \n    // 遍历所有连接，累计权重\n    for (const [sourceWord, sourceCue] of this.cues) {\n      for (const [targetWord, weight] of sourceCue.connections) {\n        const currentWeight = inWeights.get(targetWord) || 0;\n        inWeights.set(targetWord, currentWeight + weight);\n      }\n    }\n    \n    return inWeights;\n  }\n  \n  /**\n   * 获取网络统计信息\n   * \n   * @returns {Object} 统计信息\n   */\n  getStatistics() {\n    let totalConnections = 0;\n    let maxOutDegree = 0;\n    let hubNode = null;\n    let isolatedNodes = 0;\n    \n    for (const [word, cue] of this.cues) {\n      const outDegree = cue.connections.size;\n      totalConnections += outDegree;\n      \n      if (outDegree === 0) {\n        isolatedNodes++;\n      }\n      \n      if (outDegree > maxOutDegree) {\n        maxOutDegree = outDegree;\n        hubNode = word;\n      }\n    }\n    \n    const inDegrees = this.calculateInDegrees();\n    let maxInDegree = 0;\n    let sinkNode = null;\n    \n    for (const [word, inDegree] of inDegrees) {\n      if (inDegree > maxInDegree) {\n        maxInDegree = inDegree;\n        sinkNode = word;\n      }\n    }\n    \n    return {\n      totalCues: this.cues.size,\n      totalConnections,\n      averageOutDegree: this.cues.size > 0 ? totalConnections / this.cues.size : 0,\n      maxOutDegree,\n      hubNode,       // 出度最高的节点（发散中心）\n      maxInDegree,\n      sinkNode,      // 入度最高的节点（汇聚中心）\n      isolatedNodes  // 孤立节点数量\n    };\n  }\n  \n  /**\n   * 序列化Network到JSON文件\n   * \n   * 设计考虑：\n   * - 使用同步版本避免异步复杂性\n   * - 包含版本号便于未来升级\n   * - 包含时间戳便于调试\n   * \n   * @param {string} filePath - 保存路径\n   * @returns {Promise<void>}\n   */\n  async persist(filePath) {\n    try {\n      const fs = require('fs').promises;\n      const path = require('path');\n      \n      // 转换Map为可序列化的对象\n      const data = {\n        version: '1.0',\n        timestamp: Date.now(),\n        cues: {}\n      };\n      \n      // 序列化每个Cue\n      for (const [word, cue] of this.cues) {\n        data.cues[word] = cue.toJSON();\n      }\n      \n      // 确保目录存在\n      const dir = path.dirname(filePath);\n      await fs.mkdir(dir, { recursive: true });\n      \n      // 写入文件\n      await fs.writeFile(filePath, JSON.stringify(data, null, 2), 'utf8');\n      \n      logger.info('[Network] Persisted to file', { \n        path: filePath, \n        cues: this.cues.size,\n        size: JSON.stringify(data).length \n      });\n    } catch (error) {\n      logger.error('[Network] Failed to persist', { \n        path: filePath, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 从JSON文件加载Network\n   * \n   * @param {string} filePath - 文件路径\n   * @returns {Promise<void>}\n   */\n  async load(filePath) {\n    try {\n      const fs = require('fs').promises;\n      const FrequencyCue = require('./FrequencyCue');\n      \n      // 读取文件\n      const content = await fs.readFile(filePath, 'utf8');\n      const data = JSON.parse(content);\n      \n      // 版本检查\n      if (data.version !== '1.0') {\n        logger.warn('[Network] Version mismatch', { \n          expected: '1.0', \n          actual: data.version \n        });\n      }\n      \n      // 清空当前网络\n      this.cues.clear();\n      \n      // 重建所有Cue\n      for (const [word, cueData] of Object.entries(data.cues)) {\n        const cue = FrequencyCue.fromJSON(cueData);\n        this.cues.set(word, cue);\n      }\n      \n      logger.info('[Network] Loaded from file', { \n        path: filePath, \n        cues: this.cues.size,\n        timestamp: new Date(data.timestamp).toISOString()\n      });\n    } catch (error) {\n      logger.error('[Network] Failed to load', { \n        path: filePath, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 同步版本的persist\n   * \n   * Remember需要同步保存，避免异步复杂性。\n   * \n   * @param {string} filePath - 保存路径\n   */\n  persistSync(filePath) {\n    try {\n      // 转换Map为可序列化的对象\n      const data = {\n        version: '1.0',\n        timestamp: Date.now(),\n        cues: {}\n      };\n      \n      // 序列化每个Cue\n      for (const [word, cue] of this.cues) {\n        data.cues[word] = cue.toJSON();\n      }\n      \n      // 确保目录存在\n      const dir = path.dirname(filePath);\n      fs.mkdirSync(dir, { recursive: true });\n      \n      // 写入文件\n      fs.writeFileSync(filePath, JSON.stringify(data, null, 2), 'utf8');\n      \n      logger.debug('[Network] Persisted (sync) to file', { \n        path: filePath, \n        cues: this.cues.size \n      });\n    } catch (error) {\n      logger.error('[Network] Failed to persist (sync)', { \n        path: filePath, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 同步版本的load\n   * \n   * Prime需要同步加载，避免异步复杂性。\n   * \n   * @param {string} filePath - 文件路径\n   */\n  loadSync(filePath) {\n    try {\n      const FrequencyCue = require('./FrequencyCue');\n      \n      // 读取文件\n      const content = fs.readFileSync(filePath, 'utf8');\n      const data = JSON.parse(content);\n      \n      // 版本检查\n      if (data.version !== '1.0') {\n        logger.warn('[Network] Version mismatch', { \n          expected: '1.0', \n          actual: data.version \n        });\n      }\n      \n      // 清空当前网络\n      this.cues.clear();\n      \n      // 重建所有Cue\n      for (const [word, cueData] of Object.entries(data.cues)) {\n        const cue = FrequencyCue.fromJSON(cueData);\n        this.cues.set(word, cue);\n      }\n      \n      logger.debug('[Network] Loaded (sync) from file', { \n        path: filePath, \n        cues: this.cues.size \n      });\n    } catch (error) {\n      logger.error('[Network] Failed to load (sync)', { \n        path: filePath, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 更新Recall频率\n   * \n   * 当Recall操作完成后，更新所有被激活节点的频率。\n   * 这是Network作为容器管理统计信息的体现。\n   * \n   * @param {Set<string>} activatedCues - 被激活的节点集合\n   */\n  updateRecallFrequency(activatedCues) {\n    if (!activatedCues || activatedCues.size === 0) {\n      return;\n    }\n    \n    let updatedCount = 0;\n    for (const word of activatedCues) {\n      const cue = this.cues.get(word);\n      if (cue && typeof cue.incrementFrequency === 'function') {\n        cue.incrementFrequency();\n        updatedCount++;\n      }\n    }\n    \n    logger.debug('[Network] Updated recall frequencies', {\n      requested: activatedCues.size,\n      updated: updatedCount\n    });\n  }\n  \n  /**\n   * 获取频率统计信息\n   * \n   * @returns {Object} 频率统计\n   */\n  getFrequencyStatistics() {\n    let totalFrequency = 0;\n    let maxFrequency = 0;\n    let mostFrequentNode = null;\n    const frequencyDistribution = new Map();\n    \n    for (const [word, cue] of this.cues) {\n      const frequency = cue.recallFrequency || 0;\n      totalFrequency += frequency;\n      \n      if (frequency > maxFrequency) {\n        maxFrequency = frequency;\n        mostFrequentNode = word;\n      }\n      \n      // 统计频率分布\n      const bucket = Math.floor(frequency / 10) * 10; // 10为一档\n      frequencyDistribution.set(bucket, (frequencyDistribution.get(bucket) || 0) + 1);\n    }\n    \n    return {\n      totalRecalls: totalFrequency,\n      averageFrequency: this.cues.size > 0 ? totalFrequency / this.cues.size : 0,\n      maxFrequency,\n      mostFrequentNode,\n      distribution: Array.from(frequencyDistribution.entries())\n        .sort((a, b) => a[0] - b[0])\n        .map(([bucket, count]) => ({ range: `${bucket}-${bucket+9}`, count }))\n    };\n  }\n  \n  /**\n   * 清空网络\n   * \n   * 用于测试或重置。\n   */\n  clear() {\n    const previousSize = this.cues.size;\n    this.cues.clear();\n    logger.info('[Network] Cleared', { previousSize });\n  }\n}\n\nmodule.exports = Network;","/**\n * Mind - 认知网络（以 Cue 为中心的激活子图）\n * \n * ## 设计理念\n * \n * Mind代表一个当前激活的认知状态，相当于\"工作记忆\"（Working Memory）。\n * 它不是所有记忆的容器（那是Network的职责），而是当前正在思考的内容。\n * \n * 类比：\n * - Network = 长期记忆（所有你知道的）\n * - Mind = 工作记忆（你现在正在想的）\n * \n * ## 为什么这样设计\n * \n * 1. **动态激活模型**\n *    - Mind是动态生成的，不是静态存储的\n *    - 每次Recall/Prime都会生成新的Mind\n *    - 反映了人类认知的动态性：同一个概念在不同时刻激活的相关内容可能不同\n * \n * 2. **有向无环图（DAG）结构**\n *    - 从中心Cue向外扩散形成的子图\n *    - 避免环路，防止无限激活\n *    - 保持思维的方向性和层次性\n * \n * 3. **轻量级设计**\n *    - 只存储激活的Cue集合和连接关系\n *    - 不复制Cue的内容，只引用\n *    - 便于序列化和传输（给大模型）\n * \n * ## 数据结构说明\n * \n * ```javascript\n * {\n *   center: Cue实例,              // 激活中心（起点）\n *   activatedCues: Set(['认知', '模型', ...]),  // 所有激活的节点\n *   connections: [                // 激活的连接\n *     {from: '认知', to: '模型', weight: 1234567890},\n *     {from: '模型', to: '训练', weight: 1234567880}\n *   ]\n * }\n * ```\n * \n * ## Mind的用途\n * \n * 1. **作为上下文提供给大模型**\n *    - 大模型可以根据Mind理解当前的思维脉络\n *    - 提供相关概念的关联性\n * \n * 2. **可视化思维过程**\n *    - 可以渲染成mindmap\n *    - 展示概念之间的关系强度\n * \n * 3. **思维链的基础**\n *    - 多个Mind可以组合成思维链\n *    - 支持复杂的推理过程\n * \n * @class Mind\n */\nclass Mind {\n  /**\n   * 创建一个新的Mind\n   * \n   * @param {Cue} center - 中心Cue（激活的起点）\n   */\n  constructor(center) {\n    /**\n     * 激活中心 - 思维的起点\n     * \n     * 设计考虑：\n     * - 可能为null（如Prime失败或多中心激活）\n     * - 保存Cue引用而不是word，便于访问连接信息\n     * \n     * @type {Cue|null}\n     */\n    this.center = center;\n    \n    /**\n     * 激活的Cue集合 - 所有被激活的概念\n     * \n     * 使用Set的原因：\n     * - O(1)的查找性能（避免重复激活）\n     * - 自动去重\n     * - 便于统计激活数量\n     * \n     * 存储word而不是Cue引用的原因：\n     * - 减少内存占用\n     * - 便于序列化\n     * - 避免循环引用\n     * \n     * @type {Set<string>}\n     */\n    this.activatedCues = new Set();\n    \n    /**\n     * 连接关系 - 激活的边\n     * \n     * 数组结构：便于保持激活顺序\n     * 每个连接包含：\n     * - from: 源节点word\n     * - to: 目标节点word  \n     * - weight: 连接权重\n     * \n     * @type {Array<{from: string, to: string, weight: number}>}\n     */\n    this.connections = [];\n    \n    /**\n     * 多中心支持（实验性）\n     * \n     * 用于Prime.executeMultiple等场景\n     * 允许多个起点同时激活\n     * \n     * @type {Array<Cue>}\n     */\n    this.centers = [];\n    \n    /**\n     * 激活深度记录\n     * \n     * 记录每个节点距离中心的深度\n     * 用于可视化和分析\n     * \n     * @type {Map<string, number>}\n     */\n    this.depths = new Map();\n    \n    // 如果有中心，将其加入激活集合\n    if (center) {\n      this.activatedCues.add(center.word);\n      this.depths.set(center.word, 0);\n    }\n  }\n  \n  /**\n   * 添加一个激活的Cue\n   * \n   * @param {string} word - 概念词\n   * @param {number} depth - 距离中心的深度\n   */\n  addActivatedCue(word, depth = 0) {\n    this.activatedCues.add(word);\n    if (!this.depths.has(word) || this.depths.get(word) > depth) {\n      this.depths.set(word, depth);\n    }\n  }\n  \n  /**\n   * 添加一个连接\n   * \n   * @param {string} from - 源节点\n   * @param {string} to - 目标节点\n   * @param {number} weight - 连接权重\n   */\n  addConnection(from, to, weight) {\n    this.connections.push({ from, to, weight });\n    // 确保两端都在激活集合中\n    this.activatedCues.add(from);\n    this.activatedCues.add(to);\n  }\n  \n  /**\n   * 获取激活的节点数量\n   * \n   * @returns {number} 节点数\n   */\n  size() {\n    return this.activatedCues.size;\n  }\n  \n  /**\n   * 获取连接数量\n   * \n   * @returns {number} 边数\n   */\n  connectionCount() {\n    return this.connections.length;\n  }\n  \n  /**\n   * 检查是否为空Mind\n   * \n   * @returns {boolean} 是否为空\n   */\n  isEmpty() {\n    return this.activatedCues.size === 0;\n  }\n  \n  /**\n   * 获取按权重排序的连接\n   * \n   * @returns {Array} 排序后的连接\n   */\n  getSortedConnections() {\n    return [...this.connections].sort((a, b) => b.weight - a.weight);\n  }\n  \n  /**\n   * 获取特定节点的所有出边\n   * \n   * @param {string} word - 节点词\n   * @returns {Array} 出边列表\n   */\n  getOutgoingConnections(word) {\n    return this.connections.filter(conn => conn.from === word);\n  }\n  \n  /**\n   * 获取特定节点的所有入边\n   * \n   * @param {string} word - 节点词\n   * @returns {Array} 入边列表\n   */\n  getIncomingConnections(word) {\n    return this.connections.filter(conn => conn.to === word);\n  }\n  \n  /**\n   * 转换为可序列化的JSON对象\n   * \n   * 用于：\n   * - 发送给大模型\n   * - 保存思维快照\n   * - 可视化展示\n   * \n   * @returns {Object} JSON对象\n   */\n  toJSON() {\n    return {\n      center: this.center ? this.center.word : null,\n      centers: this.centers.map(c => c.word),\n      activatedCues: Array.from(this.activatedCues),\n      connections: this.connections,\n      depths: Array.from(this.depths.entries()).map(([word, depth]) => ({ word, depth })),\n      statistics: {\n        nodeCount: this.activatedCues.size,\n        edgeCount: this.connections.length,\n        maxDepth: Math.max(...this.depths.values(), 0)\n      }\n    };\n  }\n  \n  /**\n   * 生成Mermaid mindmap代码\n   * \n   * 可以直接用于可视化展示\n   * \n   * @returns {string} Mermaid mindmap代码\n   */\n  toMermaid() {\n    if (!this.center || this.activatedCues.size === 0) {\n      return 'mindmap\\n  root((空))';\n    }\n    \n    // 构建树形结构（从连接关系构建）\n    const tree = this.buildTree();\n    \n    // 生成mindmap格式\n    let mermaid = 'mindmap\\n';\n    mermaid += `  root((${this.center.word}))\\n`;\n    \n    // 递归添加子节点\n    const addChildren = (parent, indent) => {\n      const children = tree.get(parent) || [];\n      for (const child of children) {\n        mermaid += ' '.repeat(indent) + child + '\\n';\n        addChildren(child, indent + 2);\n      }\n    };\n    \n    addChildren(this.center.word, 4);\n    \n    return mermaid;\n  }\n  \n  /**\n   * 构建树形结构\n   * 用于生成mindmap\n   * \n   * @returns {Map<string, Array<string>>} 父节点 -> 子节点列表\n   */\n  buildTree() {\n    const tree = new Map();\n    const visited = new Set();\n    \n    // 从连接构建父子关系\n    for (const conn of this.connections) {\n      if (!tree.has(conn.from)) {\n        tree.set(conn.from, []);\n      }\n      // 避免重复添加\n      if (!visited.has(`${conn.from}->${conn.to}`)) {\n        tree.get(conn.from).push(conn.to);\n        visited.add(`${conn.from}->${conn.to}`);\n      }\n    }\n    \n    // 按权重排序子节点（可选）\n    for (const [parent, children] of tree) {\n      // 获取每个子节点的权重\n      const childrenWithWeight = children.map(child => {\n        const conn = this.connections.find(c => c.from === parent && c.to === child);\n        return { child, weight: conn ? conn.weight : 0 };\n      });\n      // 按权重降序排序\n      childrenWithWeight.sort((a, b) => b.weight - a.weight);\n      // 更新排序后的子节点\n      tree.set(parent, childrenWithWeight.map(item => item.child));\n    }\n    \n    return tree;\n  }\n  \n  /**\n   * 合并另一个Mind\n   * \n   * 用于多线索思考的场景\n   * \n   * @param {Mind} otherMind - 要合并的Mind\n   */\n  merge(otherMind) {\n    // 合并激活集合\n    for (const cue of otherMind.activatedCues) {\n      this.activatedCues.add(cue);\n    }\n    \n    // 合并连接（避免重复）\n    const existingConns = new Set(\n      this.connections.map(c => `${c.from}->${c.to}`)\n    );\n    \n    for (const conn of otherMind.connections) {\n      const key = `${conn.from}->${conn.to}`;\n      if (!existingConns.has(key)) {\n        this.connections.push(conn);\n      }\n    }\n    \n    // 合并深度信息\n    for (const [word, depth] of otherMind.depths) {\n      if (!this.depths.has(word) || this.depths.get(word) > depth) {\n        this.depths.set(word, depth);\n      }\n    }\n    \n    // 添加到多中心列表\n    if (otherMind.center) {\n      this.centers.push(otherMind.center);\n    }\n  }\n}\n\nmodule.exports = Mind;","const logger = require('@promptx/logger');\n\n/**\n * Engram - 记忆痕迹载体\n * \n * ## 设计理念\n * \n * Engram（记忆痕迹）是认知系统中的基本记忆单元，包含了一次认知体验的完整信息。\n * 它贯穿整个认知循环，从AI的感知理解到海马体的存储检索。\n * \n * 在神经科学中，Engram指大脑中存储特定记忆的物理或生化变化。\n * 在我们的系统中，它是连接AI大脑皮层和认知海马体的标准数据结构。\n * \n * ## 康德认识论映射\n * \n * - content = 感性直观（现象界的原始经验）\n * - schema = 知性范畴（概念化的结果）\n * - strength = 实践理性（角色的主观价值判断）\n * - timestamp = 时间形式（内感官的先验形式）\n * \n * ## 为什么需要Engram\n * \n * 1. **数据完整性**\n *    - 保留完整的认知过程信息\n *    - content用于追溯和调试\n *    - schema用于存储和检索\n * \n * 2. **职责分离**\n *    - Engram负责数据承载\n *    - Remember负责处理逻辑\n *    - 清晰的数据与算法分离\n * \n * 3. **时间一致性**\n *    - timestamp在创建时确定\n *    - 避免处理过程中的时间漂移\n *    - 保证批次内的时间统一\n * \n * @class Engram\n */\nclass Engram {\n  /**\n   * 创建记忆痕迹\n   * \n   * @param {Object} params - 参数对象\n   * @param {string} params.content - 原始经验内容\n   * @param {string|Array} params.schema - 概念序列（字符串或数组）\n   * @param {number} params.strength - 记忆强度 (0-1)，表示角色的主观重要性评分\n   * @param {number} [params.timestamp] - 时间戳（可选，默认为当前时间）\n   */\n  constructor({ content, schema, strength, timestamp }) {\n    // 验证必需参数\n    if (!content) {\n      throw new Error('Engram requires content');\n    }\n    if (!schema) {\n      throw new Error('Engram requires schema');\n    }\n    if (strength === undefined || strength === null) {\n      throw new Error('Engram requires strength');\n    }\n    \n    /**\n     * 原始经验内容\n     * 保留AI的原始理解，用于追溯和调试\n     * @type {string}\n     */\n    this.content = content;\n    \n    /**\n     * 概念序列\n     * 经过图式化处理的概念数组\n     * @type {Array<string>}\n     */\n    this.schema = this._normalizeSchema(schema);\n    \n    /**\n     * 记忆强度\n     * 角色视角的主观重要性评分 (0-1)\n     * @type {number}\n     */\n    this.strength = this._validateStrength(strength);\n    \n    /**\n     * 时间戳\n     * 记忆创建的精确时间\n     * @type {number}\n     */\n    this.timestamp = timestamp || Date.now();\n    \n    /**\n     * Engram唯一标识符\n     * 格式: timestamp_randomId\n     * @type {string}\n     */\n    this.id = `${this.timestamp}_${Math.random().toString(36).substr(2, 9)}`;\n    \n    logger.debug('[Engram] Created new engram', {\n      schemaLength: this.schema.length,\n      strength: this.strength,\n      timestamp: new Date(this.timestamp).toISOString()\n    });\n  }\n  \n  /**\n   * 标准化schema格式\n   * 支持字符串（换行分隔）或数组格式\n   * \n   * @private\n   * @param {string|Array} schema - 原始schema\n   * @returns {Array<string>} 标准化的概念数组\n   */\n  _normalizeSchema(schema) {\n    if (Array.isArray(schema)) {\n      return schema.filter(item => item && typeof item === 'string');\n    }\n    \n    if (typeof schema === 'string') {\n      // 支持换行分隔的字符串格式\n      return schema\n        .split('\\n')\n        .map(s => s.trim())\n        .filter(Boolean);\n    }\n    \n    throw new Error('Schema must be a string or array');\n  }\n  \n  /**\n   * 验证strength值的有效性\n   * \n   * @private\n   * @param {number} strength - 强度值\n   * @returns {number} 验证后的强度值\n   */\n  _validateStrength(strength) {\n    const num = Number(strength);\n    if (isNaN(num)) {\n      throw new Error('Strength must be a number');\n    }\n    if (num < 0 || num > 1) {\n      throw new Error('Strength must be between 0 and 1');\n    }\n    return num;\n  }\n  \n  /**\n   * 获取schema长度\n   * 用于快速判断是否可以创建连接\n   * \n   * @returns {number} schema数组的长度\n   */\n  get length() {\n    return this.schema.length;\n  }\n  \n  /**\n   * 判断是否有效\n   * schema至少需要2个元素才能创建连接\n   * \n   * @returns {boolean} 是否为有效的engram\n   */\n  isValid() {\n    return this.schema.length >= 2;\n  }\n  \n  /**\n   * 获取预览字符串\n   * 用于日志和调试\n   * \n   * @param {number} [maxLength=5] - 最大显示元素数\n   * @returns {string} 预览字符串\n   */\n  getPreview(maxLength = 5) {\n    const preview = this.schema.slice(0, maxLength).join(' -> ');\n    return this.schema.length > maxLength ? `${preview}...` : preview;\n  }\n  \n  /**\n   * 转换为JSON对象\n   * 用于序列化和传输\n   * \n   * @returns {Object} JSON对象\n   */\n  toJSON() {\n    return {\n      id: this.id,\n      content: this.content,\n      schema: this.schema,\n      strength: this.strength,\n      timestamp: this.timestamp\n    };\n  }\n  \n  /**\n   * 从JSON对象创建Engram\n   * 用于反序列化\n   * \n   * @static\n   * @param {Object} json - JSON对象\n   * @returns {Engram} 新的Engram实例\n   */\n  static fromJSON(json) {\n    return new Engram(json);\n  }\n}\n\nmodule.exports = Engram;","/**\n * WeightContext - 权重计算上下文\n * \n * ## 设计理念\n * \n * WeightContext封装了计算连接权重所需的所有信息。\n * 这是策略模式（Strategy Pattern）的关键部分，让权重计算与数据收集解耦。\n * \n * ## 为什么这样设计\n * \n * 1. **职责分离**\n *    - WeightContext负责收集数据\n *    - Strategy负责计算逻辑\n *    - 便于测试和扩展\n * \n * 2. **最小化原则**\n *    - 只包含实际使用的参数\n *    - 避免过度设计\n *    - 保持简洁清晰\n * \n * 3. **透明性**\n *    - 所有影响权重的因素都明确定义\n *    - 便于调试和优化\n *    - 易于理解权重的来源\n * \n * ## 权重因子说明\n * \n * 当前包含的因子：\n * 1. **时间因子（timestamp）**\n *    - 作为权重的基数\n *    - 新的记忆自然比旧的权重大\n *    - 体现记忆的时效性\n * \n * 2. **位置因子（position）**\n *    - 在Schema序列中的位置\n *    - 越靠后的连接权重越低（衰减）\n *    - 体现首因效应和近因效应\n * \n * 3. **网络因子（sourceOutDegree）**\n *    - 源节点的出度\n *    - 出度越高，每条边的权重越分散\n *    - 防止hub节点过度激活\n * \n * ## 设计决策\n * \n * Q: 为什么不包含targetCue？\n * A: 目标节点可能还不存在（Remember创建时），而且当前算法不需要目标节点信息。\n * \n * Q: 为什么sourceOutDegree要缓存？\n * A: 避免重复计算，虽然简单但频繁调用。\n * \n * Q: 为什么timestamp可以外部传入？\n * A: 同一批Schema应该使用相同的时间戳，保持批次内的一致性。\n * \n * @class WeightContext\n */\nclass WeightContext {\n  /**\n   * 创建权重计算上下文\n   * \n   * @param {Object} data - 上下文数据\n   * @param {Cue} data.sourceCue - 源节点\n   * @param {string} data.targetWord - 目标词\n   * @param {number} data.position - 在Schema中的位置\n   * @param {number} [data.timestamp] - 时间戳（可选，默认当前时间）\n   * @param {Engram} [data.engram] - 完整的记忆痕迹对象（可选）\n   */\n  constructor(data) {\n    /**\n     * 源Cue节点\n     * \n     * 包含了源节点的所有信息：\n     * - word: 概念词\n     * - connections: 所有出边\n     * \n     * @type {Cue}\n     */\n    this.sourceCue = data.sourceCue;\n    \n    /**\n     * 目标词\n     * \n     * 注意：是词而不是Cue，因为目标节点可能还不存在。\n     * Remember在创建连接时，目标Cue可能刚刚创建。\n     * \n     * @type {string}\n     */\n    this.targetWord = data.targetWord;\n    \n    /**\n     * 在Schema中的位置（0-based）\n     * \n     * 用于计算位置衰减：\n     * - position=0: 第一条边，权重最高\n     * - position=1: 第二条边，权重衰减\n     * - position=n: 权重 = base * decay^n\n     * \n     * @type {number}\n     */\n    this.position = data.position;\n    \n    /**\n     * 当前时间戳\n     * \n     * 作为权重的基数，保证：\n     * - 新的记忆权重 > 旧的记忆权重\n     * - 同批次使用相同时间戳\n     * \n     * 使用毫秒时间戳（13位数字），足够精确且不会溢出。\n     * \n     * @type {number}\n     */\n    this.timestamp = data.timestamp || Date.now();\n    \n    /**\n     * 源节点的出度（缓存）\n     * \n     * 出度 = 源节点连接到多少其他节点\n     * 用于调整权重，防止hub节点过度激活。\n     * \n     * 缓存原因：避免重复访问Map.size\n     * \n     * @type {number}\n     */\n    this.sourceOutDegree = this.sourceCue ? this.sourceCue.connections.size : 0;\n    \n    /**\n     * 完整的记忆痕迹对象\n     * \n     * 包含了记忆的完整信息：\n     * - content: 原始经验\n     * - schema: 概念序列\n     * - strength: 角色评分（0-1）\n     * - timestamp: 时间戳\n     * \n     * 让策略可以使用strength进行权重调整\n     * \n     * @type {Engram|null}\n     */\n    this.engram = data.engram || null;\n    \n    /**\n     * 记忆强度（从engram提取）\n     * \n     * 便捷访问，避免总是写this.engram.strength\n     * 默认值0.8用于向后兼容\n     * \n     * @type {number}\n     */\n    this.strength = this.engram ? this.engram.strength : 0.8;\n  }\n  \n  /**\n   * 获取源词\n   * \n   * 便捷方法，避免总是写this.sourceCue.word\n   * \n   * @returns {string|null} 源词\n   */\n  getSourceWord() {\n    return this.sourceCue ? this.sourceCue.word : null;\n  }\n  \n  /**\n   * 转换为调试字符串\n   * \n   * 用于日志输出，包含关键信息。\n   * \n   * @returns {string} 调试信息\n   */\n  toString() {\n    const sourceWord = this.getSourceWord();\n    return `WeightContext{${sourceWord}->${this.targetWord}, pos:${this.position}, degree:${this.sourceOutDegree}}`;\n  }\n  \n  /**\n   * 转换为JSON对象\n   * \n   * 用于序列化和日志记录。\n   * \n   * @returns {Object} JSON对象\n   */\n  toJSON() {\n    return {\n      sourceWord: this.getSourceWord(),\n      targetWord: this.targetWord,\n      position: this.position,\n      timestamp: this.timestamp,\n      sourceOutDegree: this.sourceOutDegree,\n      strength: this.strength\n    };\n  }\n}\n\nmodule.exports = WeightContext;","const logger = require('@promptx/logger');\n\n/**\n * Remember - 记忆写入执行器\n * \n * ## 设计理念\n * \n * Remember是记忆系统的写入端，负责将Schema（概念序列）写入Network。\n * 采用纯执行器模式，不包含任何计算逻辑，所有计算委托给Strategy。\n * \n * 类比生物记忆：\n * - Schema = 体验的序列（如\"看到-理解-记住\"）\n * - Remember = 海马体的编码过程\n * - 连接权重 = 突触强度\n * \n * ## 为什么这样设计\n * \n * 1. **职责单一**\n *    - Remember只负责执行流程，不负责算法\n *    - 便于测试和维护\n *    - 可以轻松切换不同的权重策略\n * \n * 2. **批处理优化**\n *    - 同一批Schema使用相同时间戳\n *    - 保证批次内的一致性\n *    - 避免时间戳漂移\n * \n * 3. **覆盖而非累加**\n *    - 新的记忆覆盖旧的（用户决定）\n *    - 简化模型，避免权重爆炸\n *    - 符合\"遗忘即学习\"的认知规律\n * \n * ## 执行流程\n * \n * ```\n * Schema: [\"认知\", \"模型\", \"训练\", \"效果\"]\n * \n * Phase 1: 确保Cue存在\n *   - 创建/获取 \"认知\" Cue\n *   - 创建/获取 \"模型\" Cue\n *   - 创建/获取 \"训练\" Cue\n *   - 创建/获取 \"效果\" Cue\n * \n * Phase 2: 建立连接\n *   - \"认知\" -> \"模型\" (position=0)\n *   - \"模型\" -> \"训练\" (position=1)\n *   - \"训练\" -> \"效果\" (position=2)\n * ```\n * \n * ## 设计决策\n * \n * Q: 为什么不在Remember中计算权重？\n * A: 策略模式，算法可独立演化，Remember保持稳定。\n * \n * Q: 为什么要两个Phase？\n * A: \n * - Phase 1确保所有节点存在，避免边创建时找不到节点\n * - Phase 2专注于边的创建，逻辑清晰\n * \n * Q: 为什么返回connections数组？\n * A: 便于调试、日志记录和可视化展示。\n * \n * @class Remember\n */\nclass Remember {\n  /**\n   * 创建Remember实例\n   * \n   * @param {Network} network - 全局认知网络\n   * @param {WeightStrategy} strategy - 权重计算策略\n   */\n  constructor(network, options = {}) {\n    /**\n     * 认知网络引用\n     * @type {Network}\n     */\n    this.network = network;\n    \n    /**\n     * 权重策略\n     * @type {WeightStrategy}\n     */\n    this.strategy = options.strategy || null;\n    \n    if (this.strategy) {\n      logger.debug('[Remember] Initialized with strategy', { \n        strategy: this.strategy.constructor.name \n      });\n    } else {\n      logger.warn('[Remember] No strategy provided');\n    }\n  }\n\n  /**\n   * 执行记忆写入\n   * \n   * 将Engram中的Schema序列写入Network，建立Cue之间的连接，\n   * 同时建立Cue到Engram.id的反向索引。\n   * \n   * @param {Engram} engram - 记忆痕迹对象\n   * @param {string} [engramId] - 可选的Engram ID，默认使用engram.id\n   * @returns {Object} 执行结果\n   * @returns {number} returns.processed - 处理的节点数\n   * @returns {Array} returns.connections - 创建的连接列表\n   * @returns {string} returns.engramId - 使用的Engram ID\n   */\n  execute(engram, engramId = null) {\n    // 参数验证\n    const Engram = require('./Engram');\n    if (!engram || !(engram instanceof Engram)) {\n      logger.warn('[Remember] Invalid engram provided', { engram });\n      return {\n        processed: 0,\n        connections: []\n      };\n    }\n    \n    if (!engram.isValid()) {\n      logger.debug('[Remember] Engram schema too short, no connections to create', { \n        length: engram.length \n      });\n      return {\n        processed: engram.length,\n        connections: []\n      };\n    }\n    \n    const { schema, strength, timestamp } = engram;\n    \n    logger.debug('[Remember] Processing engram', { \n      length: schema.length,\n      strength: strength,\n      preview: engram.getPreview()\n    });\n    \n    // Phase 1: 确保所有Cue存在\n    logger.debug('[Remember] Phase 1: Ensuring all Cues exist');\n    const createdCues = [];\n    for (const word of schema) {\n      // 使用Network的getOrCreateCue方法，它会创建FrequencyCue\n      if (!this.network.cues.has(word)) {\n        createdCues.push(word);\n      }\n      this.network.getOrCreateCue(word);\n    }\n    \n    if (createdCues.length > 0) {\n      logger.debug('[Remember] Created new Cues', { \n        count: createdCues.length,\n        cues: createdCues.slice(0, 10)  // 只显示前10个\n      });\n    }\n    \n    // Phase 2: 建立连接结构（先用临时权重）\n    logger.debug('[Remember] Phase 2: Building connection structure');\n    const WeightContext = require('./WeightContext');\n    const connections = [];\n    // 使用engram的timestamp，保证时间一致性\n    \n    // 2.1 先建立所有连接（用临时权重0）\n    for (let i = 0; i < schema.length - 1; i++) {\n      const sourceWord = schema[i];\n      const targetWord = schema[i + 1];\n      const sourceCue = this.network.cues.get(sourceWord);\n      \n      // 检查是否已有连接\n      const existingWeight = sourceCue.connections.get(targetWord);\n      if (!existingWeight) {\n        // 新连接，先用0占位\n        sourceCue.connections.set(targetWord, 0);\n      }\n    }\n    \n    // 2.2 现在计算并更新权重（此时出度已正确）\n    logger.debug('[Remember] Phase 2.2: Calculating and updating weights');\n    for (let i = 0; i < schema.length - 1; i++) {\n      const sourceWord = schema[i];\n      const targetWord = schema[i + 1];\n      const sourceCue = this.network.cues.get(sourceWord);\n      \n      // 构建上下文（现在sourceOutDegree是正确的）\n      const context = new WeightContext({\n        sourceCue: sourceCue,\n        targetWord: targetWord,\n        position: i,\n        timestamp: timestamp,\n        engram: engram  // 传递完整的engram对象\n      });\n      \n      // 委托策略计算权重\n      const weight = this.strategy.calculate(context);\n      \n      logger.debug('[Remember] Weight calculation', {\n        from: sourceWord,\n        to: targetWord,\n        position: i,\n        outDegree: context.sourceOutDegree,\n        weight: weight\n      });\n      \n      // 更新权重（覆盖）\n      sourceCue.connections.set(targetWord, weight);\n      \n      // 记录本次更新\n      connections.push({\n        source: sourceWord,\n        target: targetWord,\n        weight: weight,\n        position: i\n      });\n    }\n    \n    logger.info('[Remember] Schema processed successfully', {\n      nodes: schema.length,\n      connections: connections.length,\n      timestamp: new Date(timestamp).toISOString()\n    });\n    \n    // 建立Cue到Engram的反向索引\n    const actualEngramId = engramId || engram.id;\n    if (actualEngramId) {\n      for (const word of schema) {\n        const cue = this.network.cues.get(word);\n        if (cue) {\n          if (!cue.memories) {\n            cue.memories = new Set();\n          }\n          cue.memories.add(actualEngramId);\n          \n          logger.debug('[Remember] Added engram reference', {\n            cue: word,\n            engramId: actualEngramId,\n            totalReferences: cue.memories.size\n          });\n        }\n      }\n    }\n    \n    return {\n      processed: schema.length,\n      connections: connections,\n      timestamp: timestamp,\n      engramId: actualEngramId\n    };\n  }\n}\n\nmodule.exports = Remember;","const logger = require('@promptx/logger');\n\n/**\n * ActivationStrategy - 激活策略基类\n * \n * ## 设计理念\n * \n * 定义激活扩散的策略接口，让不同的激活算法可以灵活切换。\n * 这是策略模式在激活扩散中的应用。\n * \n * ## 为什么这样设计\n * \n * 1. **算法独立**\n *    - 激活算法独立于Recall的流程控制\n *    - 便于实现和测试不同的算法\n *    - 可以根据场景选择不同策略\n * \n * 2. **职责清晰**\n *    - Strategy负责决策（是否激活、如何激活）\n *    - Recall负责执行（管理流程、构建Mind）\n *    - Context负责状态（数据和状态管理）\n * \n * 3. **易于扩展**\n *    - 新算法只需继承基类\n *    - 不影响现有代码\n *    - 可以组合不同的策略\n * \n * @class ActivationStrategy\n */\nclass ActivationStrategy {\n  constructor(options = {}) {\n    /**\n     * 策略名称\n     * @type {string}\n     */\n    this.name = 'base';\n    \n    /**\n     * 策略配置\n     * @type {Object}\n     */\n    this.options = options;\n  }\n  \n  /**\n   * 决定如何激活节点\n   * \n   * 子类必须实现此方法\n   * \n   * @param {ActivationContext} context - 激活上下文\n   * @returns {Object} 激活决策\n   * @returns {boolean} returns.shouldActivate - 是否应该激活\n   * @returns {Array} returns.edges - 要激活的边列表\n   */\n  activate(context) {\n    throw new Error('ActivationStrategy.activate() must be implemented');\n  }\n  \n  /**\n   * 判断是否继续激活\n   * \n   * @param {ActivationContext} context - 激活上下文\n   * @returns {boolean} true继续，false停止\n   */\n  shouldContinue(context) {\n    return true;\n  }\n  \n  /**\n   * 应用衰减或其他周期性操作\n   * \n   * @param {ActivationContext} context - 激活上下文\n   */\n  applyDecay(context) {\n    // 默认不做任何事\n  }\n}\n\n/**\n * HippocampalActivationStrategy - 海马体激活策略\n * \n * ## 设计理念\n * \n * 模拟海马体的激活扩散机制：\n * - 能量在网络中流动和衰减\n * - 只有能量足够的节点才会激活\n * - 侧抑制防止过度激活\n * - 频率增强经常使用的连接\n * \n * ## 算法特点\n * \n * 1. **能量模型**\n *    - 初始节点满能量（1.0）\n *    - 能量通过连接传递，有损耗\n *    - 能量低于阈值的节点不再传播\n * \n * 2. **频率增强**\n *    - 经常被recall的节点更容易激活\n *    - 模拟长时程增强（LTP）效应\n * \n * 3. **侧抑制**\n *    - 激活节点越多，每个节点获得的能量越少\n *    - 保持稀疏表征\n * \n * 4. **自然终止**\n *    - 能量耗散后自然停止\n *    - 不需要硬性深度限制\n * \n * @class HippocampalActivationStrategy\n * @extends ActivationStrategy\n */\nclass HippocampalActivationStrategy extends ActivationStrategy {\n  constructor(options = {}) {\n    super(options);\n    \n    /**\n     * 策略名称\n     * @type {string}\n     */\n    this.name = 'hippocampal';\n    \n    /**\n     * 神经元激活阈值\n     * 只有能量超过此值的节点才会激活\n     * @type {number}\n     */\n    this.firingThreshold = options.firingThreshold || 0.1;  // 降低阈值，让更多节点能激活\n    \n    /**\n     * 突触传递效率\n     * 能量传递时的损耗率\n     * @type {number}\n     */\n    this.synapticDecay = options.synapticDecay || 0.9;  // 提高传递效率，减少能量损失\n    \n    /**\n     * 侧抑制因子\n     * 控制网络激活的稀疏性\n     * @type {number}\n     */\n    this.inhibitionFactor = options.inhibitionFactor || 0.1;\n    \n    /**\n     * 最大循环次数\n     * 防止无限循环的保护机制\n     * @type {number}\n     */\n    this.maxCycles = options.maxCycles || 10;\n    \n    /**\n     * 每周期能量衰减率\n     * 模拟时间流逝的能量损耗\n     * @type {number}\n     */\n    this.cycleDecay = options.cycleDecay || 0.9;\n    \n    /**\n     * 频率增强因子\n     * 控制频率对激活的影响程度\n     * @type {number}\n     */\n    this.frequencyBoost = options.frequencyBoost || 0.1;\n    \n    /**\n     * 权重策略（用于归一化和批次感知）\n     * @type {WeightStrategy|null}\n     */\n    this.weightStrategy = options.weightStrategy || null;\n    \n    logger.debug('[HippocampalActivationStrategy] Initialized', {\n      firingThreshold: this.firingThreshold,\n      synapticDecay: this.synapticDecay,\n      maxCycles: this.maxCycles\n    });\n  }\n  \n  /**\n   * 决定如何激活节点\n   * \n   * @param {ActivationContext} context - 激活上下文\n   * @returns {Object} 激活决策\n   */\n  activate(context) {\n    // 能量不足，不激活\n    if (context.currentEnergy < this.firingThreshold) {\n      logger.debug('[HippocampalActivationStrategy] Energy below threshold', {\n        word: context.sourceCue?.word,\n        energy: context.currentEnergy,\n        threshold: this.firingThreshold\n      });\n      return { shouldActivate: false, edges: [] };\n    }\n    \n    if (!context.sourceCue || !context.sourceCue.connections) {\n      return { shouldActivate: false, edges: [] };\n    }\n    \n    // 准备边数据\n    let edges = Array.from(context.sourceCue.connections.entries())\n      .map(([targetWord, weight]) => ({\n        targetWord,\n        weight,\n        frequency: context.getTargetFrequency(targetWord)\n      }));\n    \n    // 如果有权重策略，使用它进行归一化（包含温度控制和批次感知）\n    if (this.weightStrategy && typeof this.weightStrategy.normalizeForActivation === 'function') {\n      edges = this.weightStrategy.normalizeForActivation(edges);\n      logger.debug('[HippocampalActivationStrategy] Applied weight strategy normalization', {\n        strategy: this.weightStrategy.constructor.name,\n        edgeCount: edges.length\n      });\n    }\n    \n    // 基于归一化后的概率计算能量传递\n    const processedEdges = edges.map(edge => {\n      // 使用归一化后的概率（如果有）或原始权重\n      const activationProbability = edge.probability || (edge.weight / edges.reduce((sum, e) => sum + e.weight, 0));\n      \n      // 频率加成（经常被激活的节点更容易再次激活）\n      const freqBonus = 1 + Math.log(1 + edge.frequency) * this.frequencyBoost;\n      \n      // 基于概率的能量传递\n      const transmittedEnergy = context.currentEnergy * \n                               activationProbability * \n                               this.synapticDecay * \n                               freqBonus;\n      \n      // 应用侧抑制（激活节点越多，抑制越强）\n      const inhibition = 1 - (this.inhibitionFactor * context.activatedNodes.size / 100);\n      const finalEnergy = transmittedEnergy * inhibition;\n      \n      return {\n        targetWord: edge.targetWord,\n        weight: edge.weight,\n        energy: finalEnergy,\n        frequency: edge.frequency,\n        probability: activationProbability,\n        batchMultiplier: edge.batchMultiplier || 1,\n        shouldFire: finalEnergy >= this.firingThreshold\n      };\n    });\n    \n    // 只返回能量足够且未激活的边\n    const activeEdges = processedEdges.filter(e => \n      e.shouldFire && !context.isActivated(e.targetWord)\n    );\n    \n    logger.debug('[HippocampalActivationStrategy] Activation decision', {\n      source: context.sourceCue.word,\n      sourceEnergy: context.currentEnergy,\n      totalEdges: edges.length,\n      activeEdges: activeEdges.length,\n      cycle: context.cycle,\n      hasWeightStrategy: !!this.weightStrategy\n    });\n    \n    return { shouldActivate: true, edges: activeEdges };\n  }\n  \n  /**\n   * 判断是否继续激活\n   * \n   * @param {ActivationContext} context - 激活上下文\n   * @returns {boolean} true继续，false停止\n   */\n  shouldContinue(context) {\n    // 超过最大循环次数\n    if (context.cycle >= this.maxCycles) {\n      logger.debug('[HippocampalActivationStrategy] Max cycles reached', {\n        cycle: context.cycle,\n        maxCycles: this.maxCycles\n      });\n      return false;\n    }\n    \n    // 检查是否还有高能量节点\n    let hasHighEnergyNode = false;\n    for (const [word, energy] of context.energyPool) {\n      if (energy >= this.firingThreshold) {\n        hasHighEnergyNode = true;\n        break;\n      }\n    }\n    \n    if (!hasHighEnergyNode) {\n      logger.debug('[HippocampalActivationStrategy] No high energy nodes', {\n        cycle: context.cycle,\n        poolSize: context.energyPool.size\n      });\n    }\n    \n    return hasHighEnergyNode;\n  }\n  \n  /**\n   * 应用能量衰减\n   * \n   * @param {ActivationContext} context - 激活上下文\n   */\n  applyDecay(context) {\n    // 对所有节点应用时间衰减\n    for (const [word, energy] of context.energyPool) {\n      const decayedEnergy = energy * this.cycleDecay;\n      \n      // 能量太低的节点移除\n      if (decayedEnergy < 0.01) {\n        context.energyPool.delete(word);\n      } else {\n        context.energyPool.set(word, decayedEnergy);\n      }\n    }\n    \n    logger.debug('[HippocampalActivationStrategy] Applied decay', {\n      cycle: context.cycle,\n      remainingNodes: context.energyPool.size,\n      totalEnergy: Array.from(context.energyPool.values()).reduce((sum, e) => sum + e, 0).toFixed(2)\n    });\n  }\n}\n\nmodule.exports = {\n  ActivationStrategy,\n  HippocampalActivationStrategy\n};","/**\n * ActivationContext - 激活扩散上下文\n * \n * ## 设计理念\n * \n * ActivationContext封装了激活扩散过程中的所有状态和数据。\n * 与WeightContext不同，这是一个有状态的对象，会在激活过程中不断更新。\n * \n * ## 为什么这样设计\n * \n * 1. **状态管理**\n *    - 集中管理激活过程的所有状态\n *    - 避免在Recall中维护大量状态变量\n *    - 便于不同策略共享和访问状态\n * \n * 2. **策略解耦**\n *    - 策略只需要关注算法逻辑\n *    - 状态管理由Context负责\n *    - 便于实现不同的激活算法\n * \n * 3. **可扩展性**\n *    - 新策略可能需要新的状态\n *    - 通过Context统一管理\n *    - 不影响现有代码\n * \n * ## 海马体算法需要的状态\n * \n * - **能量池（energyPool）**：每个节点的当前能量水平\n * - **激活集（activatedNodes）**：已激活的节点集合\n * - **循环计数（cycle）**：当前的激活循环次数\n * - **连接记录（connections）**：已建立的连接关系\n * \n * @class ActivationContext\n */\nclass ActivationContext {\n  /**\n   * 创建激活上下文\n   * \n   * @param {Object} params - 初始参数\n   * @param {Network} params.network - 认知网络\n   * @param {Cue} params.sourceCue - 当前源节点\n   * @param {number} params.depth - 当前深度（兼容旧代码）\n   * @param {number} params.currentEnergy - 当前节点能量\n   * @param {Set} params.activatedNodes - 已激活节点集\n   * @param {Map} params.energyPool - 节点能量池\n   * @param {number} params.cycle - 循环次数\n   * @param {Array} params.connections - 连接记录\n   */\n  constructor(params = {}) {\n    /**\n     * 认知网络引用\n     * @type {Network}\n     */\n    this.network = params.network;\n    \n    /**\n     * 当前源节点\n     * @type {Cue}\n     */\n    this.sourceCue = params.sourceCue || null;\n    \n    /**\n     * 当前深度（为了兼容性保留）\n     * @type {number}\n     */\n    this.depth = params.depth || 0;\n    \n    /**\n     * 当前节点的能量水平\n     * 海马体算法的核心概念\n     * @type {number}\n     */\n    this.currentEnergy = params.currentEnergy || 1.0;\n    \n    /**\n     * 已激活的节点集合\n     * 用于避免重复激活和计算网络规模\n     * @type {Set<string>}\n     */\n    this.activatedNodes = params.activatedNodes || new Set();\n    \n    /**\n     * 能量池 - 记录每个节点的当前能量\n     * 海马体算法的核心数据结构\n     * @type {Map<string, number>}\n     */\n    this.energyPool = params.energyPool || new Map();\n    \n    /**\n     * 当前循环次数\n     * 海马体算法用于限制激活轮数\n     * @type {number}\n     */\n    this.cycle = params.cycle || 0;\n    \n    /**\n     * 连接记录\n     * 记录激活过程中建立的所有连接\n     * @type {Array<{from: string, to: string, weight: number}>}\n     */\n    this.connections = params.connections || [];\n    \n    /**\n     * 时间戳（用于日志和调试）\n     * @type {number}\n     */\n    this.timestamp = params.timestamp || Date.now();\n  }\n  \n  /**\n   * 获取目标节点的频率\n   * \n   * @param {string} targetWord - 目标词\n   * @returns {number} 频率值\n   */\n  getTargetFrequency(targetWord) {\n    const targetCue = this.network.getCue(targetWord);\n    return targetCue?.recallFrequency || 0;\n  }\n  \n  /**\n   * 检查节点是否已激活\n   * \n   * @param {string} word - 节点词\n   * @returns {boolean} 是否已激活\n   */\n  isActivated(word) {\n    return this.activatedNodes.has(word);\n  }\n  \n  /**\n   * 获取节点的当前能量\n   * \n   * @param {string} word - 节点词\n   * @returns {number} 能量值\n   */\n  getNodeEnergy(word) {\n    return this.energyPool.get(word) || 0;\n  }\n  \n  /**\n   * 设置节点能量\n   * \n   * @param {string} word - 节点词\n   * @param {number} energy - 能量值\n   */\n  setNodeEnergy(word, energy) {\n    if (energy > 0) {\n      this.energyPool.set(word, energy);\n    } else {\n      this.energyPool.delete(word);  // 能量耗尽，移除\n    }\n  }\n  \n  /**\n   * 累加节点能量\n   * \n   * @param {string} word - 节点词\n   * @param {number} energyToAdd - 要添加的能量\n   * @returns {number} 新的能量值\n   */\n  addNodeEnergy(word, energyToAdd) {\n    const current = this.getNodeEnergy(word);\n    const newEnergy = current + energyToAdd;\n    this.setNodeEnergy(word, newEnergy);\n    return newEnergy;\n  }\n  \n  /**\n   * 标记节点为已激活\n   * \n   * @param {string} word - 节点词\n   */\n  markActivated(word) {\n    this.activatedNodes.add(word);\n  }\n  \n  /**\n   * 记录连接\n   * \n   * @param {string} from - 源节点\n   * @param {string} to - 目标节点\n   * @param {number} weight - 连接权重\n   */\n  recordConnection(from, to, weight) {\n    this.connections.push({ from, to, weight });\n  }\n  \n  /**\n   * 增加循环计数\n   */\n  incrementCycle() {\n    this.cycle++;\n  }\n  \n  /**\n   * 获取统计信息\n   * \n   * @returns {Object} 统计信息\n   */\n  getStatistics() {\n    return {\n      activatedNodes: this.activatedNodes.size,\n      totalEnergy: Array.from(this.energyPool.values()).reduce((sum, e) => sum + e, 0),\n      highEnergyNodes: Array.from(this.energyPool.entries())\n        .filter(([_, energy]) => energy > 0.5)\n        .length,\n      connections: this.connections.length,\n      cycle: this.cycle\n    };\n  }\n  \n  /**\n   * 转换为调试字符串\n   * \n   * @returns {string} 调试信息\n   */\n  toString() {\n    const stats = this.getStatistics();\n    return `ActivationContext{cycle:${this.cycle}, activated:${stats.activatedNodes}, energy:${stats.totalEnergy.toFixed(2)}}`;\n  }\n}\n\nmodule.exports = ActivationContext;","const logger = require('@promptx/logger');\n\n/**\n * Recall - 记忆检索执行器\n * \n * ## 设计理念\n * \n * Recall是记忆系统的读取端，负责从Network中检索相关记忆。\n * 现在使用可插拔的激活策略，支持不同的激活扩散算法。\n * \n * ## 为什么这样设计\n * \n * 1. **策略模式**\n *    - 激活算法通过ActivationStrategy实现\n *    - 可以灵活切换不同的算法\n *    - Recall只负责流程控制\n * \n * 2. **关注点分离**\n *    - Recall：流程控制和Mind构建\n *    - ActivationStrategy：激活决策\n *    - ActivationContext：状态管理\n * \n * 3. **可扩展性**\n *    - 轻松添加新的激活算法\n *    - 不影响现有代码\n *    - 便于A/B测试不同算法\n * \n * @class Recall\n */\nclass Recall {\n  /**\n   * @param {Network} network - 全局认知网络\n   * @param {Object} options - 可选配置\n   * @param {ActivationStrategy} options.activationStrategy - 激活策略\n   * @param {WeightStrategy} options.weightStrategy - 权重策略（用于归一化）\n   */\n  constructor(network, options = {}) {\n    /**\n     * 认知网络引用\n     * @type {Network}\n     */\n    this.network = network;\n    \n    /**\n     * 权重策略（用于Softmax归一化等）\n     * @type {WeightStrategy|null}\n     */\n    this.weightStrategy = options.weightStrategy || null;\n    \n    /**\n     * 激活策略\n     * 默认使用海马体策略\n     * @type {ActivationStrategy}\n     */\n    if (options.activationStrategy) {\n      this.activationStrategy = options.activationStrategy;\n      // 如果激活策略需要权重策略，注入它\n      if (this.weightStrategy && typeof this.activationStrategy.setWeightStrategy === 'function') {\n        this.activationStrategy.setWeightStrategy(this.weightStrategy);\n      }\n    } else {\n      // 默认使用海马体策略\n      const { HippocampalActivationStrategy } = require('./ActivationStrategy');\n      this.activationStrategy = new HippocampalActivationStrategy({\n        weightStrategy: this.weightStrategy\n      });\n    }\n    \n    logger.debug('[Recall] Initialized', {\n      strategy: this.activationStrategy.name,\n      hasWeightStrategy: !!this.weightStrategy\n    });\n  }\n\n  /**\n   * 执行记忆检索\n   * \n   * @param {string} word - 起始词\n   * @returns {Mind|null} 激活的认知网络\n   */\n  execute(word) {\n    logger.debug('[Recall] Starting recall', { word });\n    \n    // 找到起始Cue\n    const centerCue = this.network.cues.get(word);\n    if (!centerCue) {\n      logger.warn('[Recall] Cue not found', { word });\n      return null;\n    }\n    \n    logger.debug('[Recall] Found center Cue', {\n      word: centerCue.word,\n      outDegree: centerCue.connections.size,\n      frequency: centerCue.recallFrequency || 0\n    });\n    \n    const Mind = require('./Mind');\n    const mind = new Mind(centerCue);\n    \n    // 创建激活上下文\n    const ActivationContext = require('./ActivationContext');\n    const context = new ActivationContext({\n      network: this.network,\n      sourceCue: centerCue,\n      energyPool: new Map([[centerCue.word, 1.0]]),  // 初始能量\n      activatedNodes: new Set([centerCue.word]),\n      connections: []\n    });\n    \n    const startTime = Date.now();\n    \n    // 激活循环\n    while (this.activationStrategy.shouldContinue(context)) {\n      const newActivations = new Map();\n      \n      // 处理当前能量池中的所有节点\n      for (const [word, energy] of context.energyPool) {\n        const sourceCue = this.network.getCue(word);\n        if (!sourceCue) continue;\n        \n        // 更新上下文\n        context.sourceCue = sourceCue;\n        context.currentEnergy = energy;\n        \n        // 获取激活决策\n        const { shouldActivate, edges } = this.activationStrategy.activate(context);\n        \n        if (shouldActivate && edges.length > 0) {\n          logger.debug('[Recall] Activating from node', {\n            source: word,\n            energy: energy.toFixed(3),\n            edgeCount: edges.length,\n            cycle: context.cycle\n          });\n          \n          // 处理每条激活的边\n          for (const edge of edges) {\n            // 累积能量（可能从多个源获得）\n            const currentEnergy = newActivations.get(edge.targetWord) || 0;\n            const totalEnergy = currentEnergy + edge.energy;\n            newActivations.set(edge.targetWord, totalEnergy);\n            \n            // 记录连接\n            mind.addConnection(word, edge.targetWord, edge.weight);\n            context.recordConnection(word, edge.targetWord, edge.weight);\n            \n            logger.debug('[Recall] Edge activated', {\n              from: word,\n              to: edge.targetWord,\n              transmittedEnergy: edge.energy.toFixed(3),\n              totalEnergy: totalEnergy.toFixed(3)\n            });\n          }\n        }\n      }\n      \n      // 清空旧能量池，使用新的\n      context.energyPool.clear();\n      \n      // 更新能量池和激活集\n      for (const [word, energy] of newActivations) {\n        context.setNodeEnergy(word, energy);\n        \n        // 能量足够高的节点标记为激活\n        if (energy >= (this.activationStrategy.firingThreshold || 0.01)) {\n          if (!context.isActivated(word)) {\n            context.markActivated(word);\n            mind.addActivatedCue(word, context.cycle + 1);  // 记录激活深度\n          }\n        }\n      }\n      \n      // 应用衰减\n      this.activationStrategy.applyDecay(context);\n      \n      // 增加循环计数\n      context.incrementCycle();\n      \n      // 如果没有新的激活，提前结束\n      if (newActivations.size === 0) {\n        logger.debug('[Recall] No new activations, stopping', {\n          cycle: context.cycle\n        });\n        break;\n      }\n    }\n    \n    const duration = Date.now() - startTime;\n    \n    // 更新节点的recall频率\n    this.network.updateRecallFrequency(context.activatedNodes);\n    \n    logger.info('[Recall] Recall completed', {\n      center: word,\n      strategy: this.activationStrategy.name,\n      cycles: context.cycle,\n      activatedNodes: context.activatedNodes.size,\n      connections: context.connections.length,\n      duration: `${duration}ms`\n    });\n    \n    return mind;\n  }\n}\n\nmodule.exports = Recall;","const logger = require('@promptx/logger');\n\n/**\n * Prime - 认知系统启动器\n * \n * ## 设计理念\n * \n * Prime是系统启动时的特殊操作，负责建立基础认知状态。\n * 类比人类的“晨起意识”：\n * - 睡醒后需要一个“启动”过程来恢复意识\n * - 基础认知状态影响整天的思维活动\n * - 不同的启动点会带来不同的认知偏向\n * \n * ## 为什么这样设计\n * \n * 1. **自动选择启动点**\n *    - 通过入度权重找到“最重要”的概念\n *    - 高入度权重 = 被多个概念强烈关联\n *    - 类似于PageRank算法的思想\n * \n * 2. **继承Recall的逻辑**\n *    - Prime本质上是特殊的Recall\n *    - 复用扩散激活的所有逻辑\n *    - 只是增加了自动选择启动词的能力\n * \n * 3. **多中心启动**\n *    - 支持从多个点同时启动\n *    - 模拟并行思维和多线索思考\n *    - 用于复杂任务的初始化\n * \n * ## 启动词选择算法\n * \n * ```\n * 对于每个节点n:\n *   inWeight(n) = Σ(weight of edges pointing to n)\n * \n * primeWord = argmax(inWeight)\n * ```\n * \n * 这个算法找到“汇聚中心”：\n * - 被多个概念指向\n * - 且连接权重高\n * - 通常是核心概念\n * \n * ## 设计决策\n * \n * Q: 为什么用入度权重而不是出度权重？\n * A: \n * - 入度高 = 被多个概念依赖，是“基础概念”\n * - 出度高 = 发散性强，是“hub节点”\n * - 启动时需要稳定的基础，不是发散的中心\n * \n * Q: 为什么支持多中心启动？\n * A: \n * - 复杂任务需要多个视角\n * - 模拟人类的并行思维\n * - 避免单一视角的偏见\n * \n * @class Prime\n * @extends Recall\n */\nconst Recall = require('./Recall');\n\nclass Prime extends Recall {\n  /**\n   * 获取默认的启动词\n   * \n   * 策略优先级：\n   * 1. 选择根节点（入度为0的节点）- 认知网络的起点\n   * 2. 选择被指向最多的节点 - 重要概念\n   * 3. 返回第一个节点 - 兜底策略\n   * \n   * @returns {string|null} 启动词\n   */\n  getPrimeWord() {\n    if (this.network.cues.size === 0) {\n      logger.warn('[Prime] Network is empty, no word to prime');\n      return null;\n    }\n    \n    logger.debug('[Prime] Calculating prime word from network', {\n      totalCues: this.network.cues.size\n    });\n    \n    // 策略1: 寻找根节点（入度为0的节点）\n    const rootNodes = this.findRootNodes();\n    if (rootNodes.length > 0) {\n      // 如果有多个根节点，选择出度最大的那个\n      const selectedRoot = rootNodes.reduce((best, current) => {\n        const currentOutDegree = this.network.cues.get(current)?.connections?.size || 0;\n        const bestOutDegree = this.network.cues.get(best)?.connections?.size || 0;\n        return currentOutDegree > bestOutDegree ? current : best;\n      });\n      \n      logger.info('[Prime] Selected root node as prime word', {\n        word: selectedRoot,\n        allRoots: rootNodes,\n        outDegree: this.network.cues.get(selectedRoot)?.connections?.size || 0\n      });\n      return selectedRoot;\n    }\n    \n    // 策略2: 选择被指向最多的节点（原逻辑）\n    const inWeights = this.network.calculateInWeights();\n    if (inWeights.size > 0) {\n      let maxWeight = 0;\n      let primeWord = null;\n      \n      for (const [word, weight] of inWeights) {\n        if (weight > maxWeight) {\n          maxWeight = weight;\n          primeWord = word;\n        }\n      }\n      \n      if (primeWord) {\n        logger.info('[Prime] Selected high in-degree node as prime word', {\n          word: primeWord,\n          inWeight: maxWeight\n        });\n        return primeWord;\n      }\n    }\n    \n    // 策略3: 返回第一个节点\n    const firstWord = this.network.cues.keys().next().value;\n    logger.debug('[Prime] Using first cue as fallback', { \n      word: firstWord \n    });\n    return firstWord;\n  }\n  \n  /**\n   * 寻找根节点（入度为0的节点）\n   * @returns {Array<string>} 根节点列表\n   */\n  findRootNodes() {\n    const hasIncomingEdge = new Set();\n    \n    // 标记所有有入边的节点\n    for (const [sourceWord, sourceCue] of this.network.cues) {\n      for (const [targetWord] of sourceCue.connections) {\n        hasIncomingEdge.add(targetWord);\n      }\n    }\n    \n    // 找出没有入边的节点（根节点）\n    const rootNodes = [];\n    for (const word of this.network.cues.keys()) {\n      if (!hasIncomingEdge.has(word)) {\n        rootNodes.push(word);\n      }\n    }\n    \n    logger.debug('[Prime] Found root nodes', {\n      count: rootNodes.length,\n      nodes: rootNodes\n    });\n    \n    return rootNodes;\n  }\n  \n  /**\n   * 执行启动\n   * \n   * @param {string} word - 可选的启动词，如果不提供则自动选择\n   * @returns {Mind|null} 基础认知状态\n   */\n  execute(word = null) {\n    logger.info('[Prime] Starting prime operation', { \n      providedWord: word,\n      autoSelect: !word,\n      networkSize: this.network.cues.size\n    });\n    \n    // 如果没有提供启动词，自动选择\n    if (!word) {\n      word = this.getPrimeWord();\n      if (!word) {\n        logger.error('[Prime] Failed to find prime word, network empty or no suitable node');\n        return null;\n      }\n      logger.info('[Prime] Auto-selected prime word', { word });\n    } else {\n      // 验证提供的词是否存在\n      if (!this.network.hasCue(word)) {\n        logger.warn('[Prime] Provided word not found in network', { word });\n        return null;\n      }\n    }\n    \n    logger.info('[Prime] Executing recall with prime word', { \n      word,\n      cueExists: this.network.hasCue(word),\n      cueConnections: this.network.cues.get(word)?.connections?.size || 0\n    });\n    \n    // 调用父类的recall逻辑\n    const mind = super.execute(word);\n    \n    if (mind) {\n      logger.info('[Prime] Prime completed successfully', {\n        primeWord: word,\n        activatedNodes: mind.activatedCues.size,\n        connections: mind.connections.length\n      });\n    } else {\n      logger.error('[Prime] Prime failed', { word });\n    }\n    \n    return mind;\n  }\n  \n  /**\n   * 多词启动（实验性功能）\n   * \n   * 同时从多个词开始激活，模拟并行思考。\n   * 生成的Mind包含多个激活中心。\n   * \n   * @param {Array<string>} words - 启动词数组\n   * @returns {Mind} 合并的认知状态\n   */\n  executeMultiple(words) {\n    logger.info('[Prime] Starting multi-center prime', {\n      words,\n      count: words.length\n    });\n    \n    const Mind = require('./Mind');\n    \n    // 创建一个合并的Mind\n    const mergedMind = new Mind(null);  // 没有单一中心\n    mergedMind.centers = [];  // 多个中心\n    \n    const validCenters = [];\n    const missingWords = [];\n    \n    // 对每个词分别执行recall\n    for (const word of words) {\n      const cue = this.network.cues.get(word);\n      if (!cue) {\n        missingWords.push(word);\n        logger.warn('[Prime] Word not found in network', { word });\n        continue;\n      }\n      \n      validCenters.push(word);\n      mergedMind.centers.push(cue);\n      \n      logger.debug('[Prime] Spreading from center', {\n        word,\n        outDegree: cue.connections.size\n      });\n      \n      // 扩散激活（重用spread方法）\n      this.spread(cue, mergedMind, [], 0);\n    }\n    \n    logger.info('[Prime] Multi-center prime completed', {\n      requestedWords: words.length,\n      validCenters: validCenters.length,\n      missingWords,\n      activatedNodes: mergedMind.activatedCues.size,\n      connections: mergedMind.connections.length\n    });\n    \n    return mergedMind;\n  }\n}\n\nmodule.exports = Prime;","const { Level } = require('level');\nconst logger = require('@promptx/logger');\n\n/**\n * Memory - 记忆内容存储\n * \n * ## 设计理念\n * \n * Memory是纯粹的KV存储，负责持久化Engram对象的完整内容。\n * 它不知道角色(role)概念，只提供简单的存储和检索功能。\n * \n * ## 存储格式\n * \n * - Key: `${timestamp}_${randomId}` (确保唯一性)\n * - Value: Engram.toJSON() 的完整对象\n * \n * ## 设计决策\n * \n * Q: 为什么用LevelDB而不是文件?\n * A: LevelDB提供事务、压缩、并发访问，更适合频繁读写\n * \n * Q: 为什么不在Memory中管理role?\n * A: 职责分离，Memory只管存储，role由上层管理\n * \n * @class Memory\n */\nclass Memory {\n  /**\n   * 创建Memory实例\n   * \n   * @param {string} dbPath - LevelDB数据库路径\n   */\n  constructor(dbPath) {\n    /**\n     * LevelDB数据库实例\n     * @type {Level}\n     */\n    this.db = new Level(dbPath, { \n      valueEncoding: 'json'  // 自动JSON序列化/反序列化\n    });\n    \n    logger.debug('[Memory] Initialized', { dbPath });\n  }\n  \n  /**\n   * 存储Engram对象\n   * \n   * @param {Engram} engram - 要存储的Engram对象\n   * @returns {Promise<string>} Engram的id（作为存储key）\n   */\n  async store(engram) {\n    // 使用engram的id作为key\n    const key = engram.id;\n    \n    try {\n      await this.db.put(key, engram.toJSON());\n      \n      logger.debug('[Memory] Stored engram', { \n        key,\n        preview: engram.getPreview(),\n        strength: engram.strength\n      });\n      \n      return key;\n    } catch (error) {\n      logger.error('[Memory] Failed to store engram', { \n        key, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 获取Engram对象\n   * \n   * @param {string} key - 存储key\n   * @returns {Promise<Object|null>} Engram数据对象，不存在时返回null\n   */\n  async get(key) {\n    try {\n      const data = await this.db.get(key);\n      \n      logger.debug('[Memory] Retrieved engram', { \n        key,\n        hasContent: !!data.content\n      });\n      \n      return data;\n    } catch (error) {\n      if (error.notFound) {\n        logger.debug('[Memory] Engram not found', { key });\n        return null;\n      }\n      \n      logger.error('[Memory] Failed to retrieve engram', { \n        key, \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 关闭数据库连接\n   * \n   * @returns {Promise<void>}\n   */\n  async close() {\n    try {\n      await this.db.close();\n      logger.debug('[Memory] Database closed');\n    } catch (error) {\n      logger.error('[Memory] Failed to close database', { \n        error: error.message \n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * 获取存储统计信息\n   * \n   * @returns {Promise<Object>} 统计信息\n   */\n  async getStatistics() {\n    try {\n      let count = 0;\n      for await (const [key] of this.db.iterator()) {\n        count++;\n      }\n      \n      return {\n        totalEngrams: count,\n        dbPath: this.db.location\n      };\n    } catch (error) {\n      logger.error('[Memory] Failed to get statistics', { \n        error: error.message \n      });\n      return {\n        totalEngrams: 0,\n        dbPath: this.db.location,\n        error: error.message\n      };\n    }\n  }\n}\n\nmodule.exports = Memory;","/**\n * WeightStrategy - 权重计算策略接口\n * \n * ## 设计理念\n * \n * 采用策略模式（Strategy Pattern）来封装权重计算算法，让算法可以独立变化。\n * 这样设计的好处是：\n * - 算法与使用者（Remember）解耦\n * - 便于测试不同的权重算法\n * - 支持运行时切换策略\n * \n * ## 为什么这样设计\n * \n * 1. **可扩展性**\n *    - 未来可能需要不同的权重算法（如基于频率、基于重要性等）\n *    - 不同场景可能需要不同的策略（学习模式 vs 复习模式）\n *    - 避免在Remember类中写死算法\n * \n * 2. **测试友好**\n *    - 可以独立测试每个策略\n *    - 可以使用mock策略进行单元测试\n *    - 便于对比不同策略的效果\n * \n * 3. **关注点分离**\n *    - Remember只负责构建网络结构\n *    - Strategy只负责计算权重\n *    - WeightContext负责传递数据\n * \n * ## 策略接口约定\n * \n * 所有策略必须实现calculate方法：\n * - 输入：WeightContext对象（包含所有计算所需信息）\n * - 输出：number类型的权重值\n * - 约束：权重应该是正数，且有合理的数值范围\n * \n * @class WeightStrategy\n */\nclass WeightStrategy {\n  /**\n   * 计算权重\n   * \n   * 子类必须实现此方法。\n   * \n   * @param {WeightContext} context - 计算上下文\n   * @param {Cue} context.sourceCue - 源节点\n   * @param {string} context.targetWord - 目标词\n   * @param {number} context.position - 在Schema中的位置\n   * @param {number} context.timestamp - 时间戳\n   * @param {number} context.sourceOutDegree - 源节点出度\n   * @returns {number} 计算得出的权重（应为正数）\n   */\n  calculate(context) {\n    throw new Error('WeightStrategy.calculate() must be implemented');\n  }\n  \n  /**\n   * 激活时归一化（用于Recall）\n   * \n   * 将一组边的权重转换为激活概率\n   * 默认实现：简单归一化\n   * \n   * @param {Array} edges - 边数组 [{targetWord, weight}, ...]\n   * @returns {Array} 归一化后的边数组，添加了probability字段\n   */\n  normalizeForActivation(edges) {\n    if (edges.length === 0) return edges;\n    \n    // 默认：简单归一化\n    const totalWeight = edges.reduce((sum, e) => sum + e.weight, 0);\n    return edges.map(edge => ({\n      ...edge,\n      probability: edge.weight / totalWeight\n    }));\n  }\n}\n\n/**\n * SimpleWeightStrategy - 简单权重策略\n * \n * ## 设计理念\n * \n * 最简单的权重策略，只考虑位置因素。\n * 适用于测试或者不需要复杂权重计算的场景。\n * \n * ## 算法说明\n * \n * weight = baseWeight * decay^position\n * \n * - baseWeight: 基础权重（默认1.0）\n * - decay: 衰减率（默认0.9）\n * - position: 在Schema中的位置（0-based）\n * \n * 例子：\n * - position=0: weight = 1.0 * 0.9^0 = 1.0\n * - position=1: weight = 1.0 * 0.9^1 = 0.9\n * - position=2: weight = 1.0 * 0.9^2 = 0.81\n * \n * @class SimpleWeightStrategy\n * @extends WeightStrategy\n */\nclass SimpleWeightStrategy extends WeightStrategy {\n  constructor(options = {}) {\n    super();\n    \n    /**\n     * 基础权重\n     * @type {number}\n     */\n    this.baseWeight = options.baseWeight || 1.0;\n    \n    /**\n     * 位置衰减率\n     * @type {number}\n     */\n    this.decay = options.decay || 0.9;\n  }\n  \n  /**\n   * 计算权重\n   * \n   * @param {WeightContext} context - 计算上下文\n   * @returns {number} 权重值\n   */\n  calculate(context) {\n    // 简单的位置衰减\n    const weight = this.baseWeight * Math.pow(this.decay, context.position);\n    return weight;\n  }\n}\n\n/**\n * TimeBasedWeightStrategy - 基于时间戳的权重策略（核心策略）\n * \n * ## 设计理念\n * \n * 这是我们的核心权重策略，基于认知心理学和神经网络原理设计。\n * \n * ### 存储阶段（Remember）\n * 权重编码了两个维度的信息：\n * 1. **时间维度**：新的记忆自然比旧的权重大\n * 2. **序列维度**：序列中越靠后的连接权重越低\n * \n * ### 激活阶段（Recall）\n * 使用Softmax归一化模拟神经网络激活：\n * - 将权重转换为概率分布\n * - 高权重连接有更高的激活概率\n * - 自然实现了选择性激活\n * \n * ## 算法公式\n * \n * ### 存储权重\n * ```\n * weight = timestamp × decay^position\n * ```\n * \n * ### 激活概率（Softmax）\n * ```\n * probability_i = exp(log(weight_i)) / Σexp(log(weight))\n * ```\n * \n * 参数说明：\n * - **timestamp**: 时间戳基数（毫秒），保证新记忆 > 旧记忆\n * - **decay**: 位置衰减率（默认0.9），体现序列中的重要性递减\n * - **position**: 在Schema中的位置（0-based）\n * \n * ## 设计决策\n * \n * Q: 为什么不在存储时考虑出度？\n * A: \n * - 存储时保持完整权重，激活时通过Softmax自然调节\n * - Softmax自动实现了\"能量守恒\"：概率总和为1\n * - 更像真实神经网络的激活模式\n * \n * Q: 为什么用Softmax而不是简单归一化？\n * A:\n * - Softmax放大差异，强者更强\n * - 符合神经网络的winner-take-all机制\n * - 自然形成选择性激活\n * \n * ## 计算示例\n * \n * 假设：\n * - timestamp = 1700000000000\n * - position = 2\n * - decay = 0.9\n * \n * 存储权重：\n * - weight = 1700000000000 * 0.9^2 = 1377000000000\n * \n * 激活时（假设有3条边）：\n * - 边1: 1700000000000 → 概率 35%\n * - 边2: 1530000000000 → 概率 33%\n * - 边3: 1377000000000 → 概率 32%\n * \n * @class TimeBasedWeightStrategy\n * @extends WeightStrategy\n */\nclass TimeBasedWeightStrategy extends WeightStrategy {\n  constructor(options = {}) {\n    super();\n    \n    /**\n     * 位置衰减率\n     * 控制序列中权重的递减速度\n     * @type {number}\n     */\n    this.decay = options.decay || 0.9;\n    \n    /**\n     * 激活阈值\n     * 低于此概率的边不激活\n     * @type {number}\n     */\n    this.activationThreshold = options.activationThreshold || 0.05;  // 5%\n    \n    /**\n     * 频率因子\n     * 控制频率对激活概率的影响程度\n     * @type {number}\n     */\n    this.frequencyFactor = options.frequencyFactor || 0.1;\n    \n    /**\n     * Network引用（用于获取频率）\n     * 由CognitionSystem注入\n     * @type {Network|null}\n     */\n    this.network = null;\n  }\n  \n  /**\n   * 计算存储权重\n   * \n   * @param {WeightContext} context - 计算上下文\n   * @returns {number} 权重值\n   */\n  calculate(context) {\n    // 时间戳作为基数\n    const timestamp = context.timestamp;\n    \n    // 位置衰减因子\n    const positionFactor = Math.pow(this.decay, context.position);\n    \n    // 角色强度因子（从engram获取）\n    const strengthFactor = context.strength || 0.8;\n    \n    // 最终权重：时间 * 位置衰减 * 角色强度\n    const weight = timestamp * positionFactor * strengthFactor;\n    \n    return weight;\n  }\n  \n  /**\n   * Softmax归一化（用于激活）\n   * \n   * 加入频率偏置，实现\"越用越强\"的效果\n   * \n   * @param {Array} edges - 边数组\n   * @returns {Array} 归一化后的边数组\n   */\n  normalizeForActivation(edges) {\n    if (edges.length === 0) return edges;\n    \n    // 计算带频率偏置的对数权重\n    const enhancedEdges = edges.map(edge => {\n      // 获取目标节点的频率\n      let frequency = 0;\n      if (this.network) {\n        const targetCue = this.network.cues.get(edge.targetWord);\n        frequency = targetCue ? (targetCue.recallFrequency || 0) : 0;\n      }\n      \n      // 在对数空间添加频率偏置\n      const logWeight = Math.log(edge.weight);\n      const frequencyBias = Math.log(1 + frequency * this.frequencyFactor);\n      \n      return {\n        ...edge,\n        adjustedLogWeight: logWeight + frequencyBias,\n        frequency\n      };\n    });\n    \n    // 找出最大值（避免数值溢出）\n    const maxLogWeight = Math.max(...enhancedEdges.map(e => e.adjustedLogWeight));\n    \n    // 计算exp(adjustedLogWeight - max)\n    const expWeights = enhancedEdges.map(e => \n      Math.exp(e.adjustedLogWeight - maxLogWeight)\n    );\n    const sumExp = expWeights.reduce((a, b) => a + b, 0);\n    \n    // 计算概率并排序\n    const normalizedEdges = edges.map((edge, i) => ({\n      ...edge,\n      probability: expWeights[i] / sumExp,\n      frequency: enhancedEdges[i].frequency\n    })).sort((a, b) => b.probability - a.probability);\n    \n    // 过滤掉概率太低的边\n    return normalizedEdges.filter(edge => edge.probability >= this.activationThreshold);\n  }\n}\n\n/**\n * TemperatureWeightStrategy - 温度控制的权重策略\n * \n * ## 设计理念\n * \n * 基于深度学习中的temperature-controlled softmax，解决hub节点语义污染问题。\n * 通过温度参数控制概率分布的\"锐度\"，实现批次隔离和创造性平衡。\n * \n * ### 核心创新\n * 1. **批次感知**：利用timestamp作为天然的批次指纹\n * 2. **温度控制**：动态调节激活的集中度\n * 3. **对比度调节**：保留归一化的同时维持批次差异\n * \n * ## 温度参数效果\n * \n * - **低温（0.1-0.5）**：锐化差异，强化同批次连接\n * - **常温（0.8-1.2）**：平衡模式，适度扩散\n * - **高温（1.5-2.0）**：平滑差异，鼓励跨批次探索\n * \n * ## 算法公式\n * \n * ### 带温度的Softmax\n * ```\n * probability_i = exp((weight_i + batch_bonus_i) / T) / Σexp((weight_j + batch_bonus_j) / T)\n * ```\n * \n * 其中：\n * - T: 温度参数\n * - batch_bonus: 批次奖励（同批次获得额外权重）\n * \n * @class TemperatureWeightStrategy\n * @extends TimeBasedWeightStrategy\n */\nclass TemperatureWeightStrategy extends TimeBasedWeightStrategy {\n  constructor(options = {}) {\n    super(options);\n    \n    /**\n     * 温度参数\n     * 控制概率分布的锐度\n     * @type {number}\n     */\n    this.temperature = options.temperature || 0.5;\n    \n    /**\n     * 对比度模式\n     * 'auto' | 'low' | 'medium' | 'high'\n     * @type {string}\n     */\n    this.contrastMode = options.contrastMode || 'auto';\n  }\n  \n  /**\n   * 设置对比度级别\n   * \n   * @param {'low'|'medium'|'high'} level - 对比度级别\n   */\n  setContrastLevel(level) {\n    const contrastMap = {\n      'low': 2.0,    // 高温，低对比度（~20%差异）\n      'medium': 1.0,  // 常温，中等对比度（~50%差异）\n      'high': 0.3     // 低温，高对比度（~80%差异）\n    };\n    \n    this.temperature = contrastMap[level] || 1.0;\n    this.contrastMode = level;\n  }\n  \n  /**\n   * 设置对比度百分比\n   * \n   * @param {number} percentage - 对比度百分比（0-100）\n   */\n  setContrastPercentage(percentage) {\n    // 0% = 完全平均（高温），100% = 极度锐化（低温）\n    const clampedPercentage = Math.max(0, Math.min(100, percentage));\n    this.temperature = 2.0 - (clampedPercentage / 100) * 1.8;\n    this.contrastMode = 'custom';\n  }\n  \n  \n  /**\n   * 自动调节温度（基于网络状态）\n   * \n   * @param {Array} edges - 边数组\n   * @returns {number} 调节后的温度\n   */\n  autoAdjustTemperature(edges) {\n    if (this.contrastMode !== 'auto') {\n      return this.temperature;\n    }\n    \n    // 计算hub密度（高连接数节点的比例）\n    const avgConnections = edges.length;\n    const hubThreshold = 5;\n    \n    if (avgConnections > hubThreshold * 2) {\n      // 超级hub节点：降低温度，增强选择性\n      return 0.3;\n    } else if (avgConnections > hubThreshold) {\n      // 普通hub节点：中低温度\n      return 0.5;\n    } else {\n      // 普通节点：常温\n      return 1.0;\n    }\n  }\n  \n  /**\n   * 带温度控制的Softmax归一化\n   * \n   * 核心思想：\n   * - 权重本身已包含timestamp信息（weight = timestamp * decay^position）\n   * - 同批次的权重数量级相近，不同批次差异巨大\n   * - 温度控制这种差异的影响程度\n   * \n   * @param {Array} edges - 边数组\n   * @returns {Array} 归一化后的边数组\n   */\n  normalizeForActivation(edges) {\n    if (edges.length === 0) return edges;\n    \n    // 自动调节温度\n    const effectiveTemperature = this.autoAdjustTemperature(edges);\n    \n    // 计算带频率偏置的对数权重\n    const enhancedEdges = edges.map(edge => {\n      // 获取频率（继承自父类）\n      let frequency = 0;\n      if (this.network) {\n        const targetCue = this.network.cues.get(edge.targetWord);\n        frequency = targetCue ? (targetCue.recallFrequency || 0) : 0;\n      }\n      \n      // 在对数空间处理（权重已包含timestamp信息）\n      const logWeight = Math.log(edge.weight);\n      const frequencyBias = Math.log(1 + frequency * this.frequencyFactor);\n      \n      return {\n        ...edge,\n        adjustedLogWeight: logWeight + frequencyBias,\n        frequency\n      };\n    });\n    \n    // 找出最大值（数值稳定性）\n    const maxLogWeight = Math.max(...enhancedEdges.map(e => e.adjustedLogWeight));\n    \n    // 带温度的softmax计算\n    // 低温：放大权重差异（同批次权重相近，会一起被选中）\n    // 高温：平滑权重差异（允许跨批次激活）\n    const expWeights = enhancedEdges.map(e => \n      Math.exp((e.adjustedLogWeight - maxLogWeight) / effectiveTemperature)\n    );\n    const sumExp = expWeights.reduce((a, b) => a + b, 0);\n    \n    // 计算概率并排序\n    const normalizedEdges = enhancedEdges.map((edge, i) => ({\n      ...edges[i],\n      probability: expWeights[i] / sumExp,\n      frequency: edge.frequency,\n      temperature: effectiveTemperature\n    })).sort((a, b) => b.probability - a.probability);\n    \n    // 过滤掉概率太低的边\n    return normalizedEdges.filter(edge => edge.probability >= this.activationThreshold);\n  }\n  \n}\n\nmodule.exports = {\n  WeightStrategy,\n  SimpleWeightStrategy,\n  TimeBasedWeightStrategy,\n  TemperatureWeightStrategy\n};","const logger = require('@promptx/logger');\nconst Network = require('./Network');\nconst Remember = require('./Remember');\nconst Recall = require('./Recall');\nconst Prime = require('./Prime');\nconst Memory = require('./Memory');\nconst { TemperatureWeightStrategy } = require('./WeightStrategy');\n\n/**\n * CognitionSystem - 认知系统主控制器\n * \n * ## 设计理念\n * \n * CognitionSystem是整个认知模块的门面（Facade），统一管理所有认知操作。\n * 它协调Network、Remember、Recall、Prime等组件，提供简单的API。\n * \n * ## 为什么这样设计\n * \n * 1. **统一入口**\n *    - 外部只需要与CognitionSystem交互\n *    - 隐藏内部复杂性\n *    - 便于版本升级和重构\n * \n * 2. **生命周期管理**\n *    - 管理Network的创建和销毁\n *    - 协调各操作的执行顺序\n *    - 处理频率更新等统计任务\n * \n * 3. **策略注入**\n *    - 统一的权重策略配置\n *    - 确保Remember和Recall使用相同策略\n *    - 便于切换不同的策略实现\n * \n * ## 架构位置\n * \n * ```\n * 用户代码\n *    ↓\n * CognitionSystem (协调器)\n *    ├── Network (容器)\n *    ├── Remember (写)\n *    ├── Recall (读)\n *    └── Prime (启动)\n * ```\n * \n * @class CognitionSystem\n */\nclass CognitionSystem {\n  /**\n   * 创建认知系统\n   * \n   * @param {Object} options - 配置选项\n   * @param {string} options.dataPath - 数据文件路径\n   * @param {Object} options.strategyOptions - 策略配置\n   * @param {Object} options.rememberOptions - Remember配置\n   * @param {Object} options.recallOptions - Recall配置\n   */\n  constructor(options = {}) {\n    /**\n     * 数据持久化路径\n     * @type {string}\n     */\n    this.dataPath = options.dataPath || './cognition.json';\n    \n    /**\n     * 全局认知网络\n     * @type {Network}\n     */\n    this.network = new Network();\n    \n    /**\n     * 权重计算策略\n     * @type {WeightStrategy}\n     */\n    this.strategy = new TemperatureWeightStrategy({\n      decay: 0.9,\n      activationThreshold: 0.01,  // 降低过滤阈值\n      frequencyFactor: 0.1,  // 频率因子\n      temperature: 0.8,      // 提高温度，允许适度扩散\n      contrastMode: 'auto',  // 自动调节对比度\n      ...options.strategyOptions\n    });\n    \n    // 让策略能访问network（用于获取频率）\n    this.strategy.network = this.network;\n    \n    /**\n     * Remember引擎配置\n     * @type {Object}\n     */\n    this.rememberOptions = {\n      ...options.rememberOptions,\n      strategy: this.strategy\n    };\n    \n    /**\n     * Recall引擎配置\n     * @type {Object}\n     */\n    this.recallOptions = {\n      ...options.recallOptions,\n      weightStrategy: this.strategy  // 传递权重策略\n    };\n    \n    /**\n     * Remember引擎实例（延迟创建）\n     * @type {Remember|null}\n     */\n    this.rememberEngine = null;\n    \n    /**\n     * Recall引擎实例（延迟创建）\n     * @type {Recall|null}\n     */\n    this.recallEngine = null;\n    \n    /**\n     * Memory存储实例（延迟创建）\n     * @type {Memory|null}\n     */\n    this.memory = null;\n    \n    logger.info('[CognitionSystem] Initialized', {\n      dataPath: this.dataPath,\n      strategyType: this.strategy.constructor.name\n    });\n  }\n  \n  /**\n   * 获取Remember引擎（懒加载）\n   * \n   * @returns {Remember}\n   */\n  getRememberEngine() {\n    if (!this.rememberEngine) {\n      this.rememberEngine = new Remember(this.network, this.rememberOptions);\n    }\n    return this.rememberEngine;\n  }\n  \n  /**\n   * 获取Recall引擎（懒加载）\n   * \n   * @returns {Recall}\n   */\n  getRecallEngine() {\n    if (!this.recallEngine) {\n      this.recallEngine = new Recall(this.network, this.recallOptions);\n    }\n    return this.recallEngine;\n  }\n  \n  /**\n   * 获取Memory存储（懒加载）\n   * \n   * @returns {Memory|null} Memory实例，如果没有directory则返回null\n   */\n  getMemory() {\n    if (!this.memory && this.network.directory) {\n      const path = require('path');\n      const memoryPath = path.join(this.network.directory, 'engrams.db');\n      this.memory = new Memory(memoryPath);\n    }\n    return this.memory;\n  }\n  \n  /**\n   * 记忆操作\n   * \n   * 执行流程：\n   * 1. 存储Engram到Memory（使用engram.id）\n   * 2. 调用Remember引擎处理Schema连接\n   * 3. 建立Cue到Engram.id的反向索引\n   * \n   * @param {Engram} engram - 记忆痕迹对象\n   * @returns {Promise<Object>} 记忆结果\n   */\n  async remember(engram) {\n    logger.debug('[CognitionSystem] Remember operation', {\n      id: engram.id,\n      schemaLength: engram.length,\n      strength: engram.strength,\n      preview: engram.getPreview()\n    });\n    \n    // 存储到Memory（使用engram.id作为key）\n    if (this.getMemory()) {\n      try {\n        await this.getMemory().store(engram);\n        logger.debug('[CognitionSystem] Stored engram to memory', { id: engram.id });\n      } catch (error) {\n        logger.error('[CognitionSystem] Failed to store engram to memory', { \n          id: engram.id,\n          error: error.message \n        });\n        throw error;\n      }\n    }\n    \n    const remember = this.getRememberEngine();\n    const result = remember.execute(engram, engram.id);\n    \n    // 注意：持久化由CognitionManager.saveSystem()负责\n    // 这里不再自动保存，避免路径冲突\n    \n    return result;\n  }\n  \n  /**\n   * 回忆操作\n   * \n   * 执行流程：\n   * 1. 调用Recall引擎激活网络\n   * 2. 加载与原始查询相关的Engrams\n   * 3. 更新被激活节点的频率\n   * 4. 返回激活的Mind（包含engrams）\n   * \n   * @param {string} word - 起始概念\n   * @returns {Promise<Mind|null>} 激活的认知网络\n   */\n  async recall(word) {\n    logger.debug('[CognitionSystem] Recall operation', { word });\n    \n    const recall = this.getRecallEngine();\n    const mind = recall.execute(word);\n    \n    if (!mind) {\n      return null;\n    }\n    \n    // 加载与原始查询直接相关的engrams\n    if (this.getMemory()) {\n      try {\n        await this.loadEngrams(mind, word);\n      } catch (error) {\n        logger.error('[CognitionSystem] Failed to load engrams', { error: error.message });\n        // 不影响recall的核心功能，继续执行\n      }\n    }\n    \n    // 更新频率\n    if (mind.activatedCues.size > 0) {\n      this.network.updateRecallFrequency(mind.activatedCues);\n      logger.debug('[CognitionSystem] Updated frequencies after recall', {\n        activatedCount: mind.activatedCues.size\n      });\n    }\n    \n    return mind;\n  }\n  \n  /**\n   * 加载与查询词直接相关的Engrams\n   * \n   * @param {Mind} mind - Mind对象\n   * @param {string} originalQuery - 原始查询词\n   * @returns {Promise<void>}\n   */\n  async loadEngrams(mind, originalQuery) {\n    mind.engrams = [];\n    \n    // Debug logging for loadEngrams process\n    logger.info('[CognitionSystem] DEBUG - loadEngrams process:', {\n      originalQuery,\n      networkCuesSize: this.network.cues.size,\n      hasMemorySystem: !!this.getMemory(),\n      networkCuesKeys: Array.from(this.network.cues.keys())\n    });\n    \n    // 只加载与原始查询词直接相关的engrams\n    const queryCue = this.network.cues.get(originalQuery);\n    \n    logger.info('[CognitionSystem] DEBUG - queryCue lookup:', {\n      originalQuery,\n      hasQueryCue: !!queryCue,\n      queryCueMemories: queryCue?.memories,\n      memoriesLength: queryCue?.memories?.length\n    });\n    \n    if (queryCue && queryCue.memories) {\n      for (const engramId of queryCue.memories) {\n        const engramData = await this.getMemory().get(engramId);\n        \n        logger.debug('[CognitionSystem] DEBUG - loading engram:', {\n          engramId,\n          hasEngramData: !!engramData,\n          engramContent: engramData?.content?.substring(0, 50)\n        });\n        \n        if (engramData) {\n          mind.engrams.push({\n            id: engramData.id,\n            content: engramData.content,\n            schema: engramData.schema,\n            strength: engramData.strength,\n            timestamp: engramData.timestamp,\n            activatedBy: originalQuery\n          });\n        }\n      }\n    } else {\n      logger.info('[CognitionSystem] DEBUG - No engrams loaded - reason:', {\n        hasQueryCue: !!queryCue,\n        hasMemories: !!queryCue?.memories,\n        query: originalQuery\n      });\n    }\n    \n    logger.debug('[CognitionSystem] Loaded engrams', { \n      query: originalQuery,\n      engramCount: mind.engrams.length \n    });\n  }\n  \n  /**\n   * 启动操作\n   * \n   * 执行流程：\n   * 1. 从磁盘加载Network\n   * 2. 使用Prime选择起始点\n   * 3. 执行预热Recall\n   * \n   * @returns {Mind|null} 预热的认知网络\n   */\n  async prime() {\n    logger.debug('[CognitionSystem] Prime operation');\n    \n    // 注意：数据加载已由CognitionManager.getSystem()完成\n    // 这里直接使用已加载的network，不再重复加载\n    logger.info('[CognitionSystem] Using existing network', {\n      cues: this.network.size()\n    });\n    \n    // 使用Prime执行启动，Prime.execute()已经包含了选择启动词和执行recall的逻辑\n    const prime = new Prime(this.network);\n    const mind = prime.execute();\n    \n    if (!mind) {\n      logger.warn('[CognitionSystem] Prime found no suitable starting point or recall failed');\n      return null;\n    }\n    \n    logger.info('[CognitionSystem] Prime completed', {\n      activatedNodes: mind.activatedCues?.size || 0,\n      connections: mind.connections?.length || 0,\n      centerWord: mind.centerWord\n    });\n    \n    // 加载与prime中心词相关的engrams\n    if (this.getMemory() && mind.centerWord) {\n      try {\n        await this.loadEngrams(mind, mind.centerWord);\n        logger.info('[CognitionSystem] Loaded engrams for prime center word', {\n          centerWord: mind.centerWord,\n          engramCount: mind.engrams?.length || 0\n        });\n      } catch (error) {\n        logger.error('[CognitionSystem] Failed to load engrams for prime', { \n          centerWord: mind.centerWord,\n          error: error.message \n        });\n        // 不影响prime的核心功能，继续执行\n      }\n    }\n    \n    // Prime时不更新频率，因为这是系统自动触发的\n    \n    return mind;\n  }\n  \n  /**\n   * 获取系统统计信息\n   * \n   * @returns {Object} 统计信息\n   */\n  getStatistics() {\n    const networkStats = this.network.getStatistics();\n    const frequencyStats = this.network.getFrequencyStatistics();\n    \n    return {\n      network: networkStats,\n      frequency: frequencyStats,\n      dataPath: this.dataPath,\n      strategy: {\n        type: this.strategy.constructor.name,\n        decay: this.strategy.decay,\n        frequencyFactor: this.strategy.frequencyFactor || 0\n      }\n    };\n  }\n  \n  /**\n   * 清空系统\n   * \n   * 用于测试或重置。\n   */\n  clear() {\n    this.network.clear();\n    this.rememberEngine = null;\n    this.recallEngine = null;\n    logger.info('[CognitionSystem] System cleared');\n  }\n  \n  /**\n   * 手动保存\n   * \n   * 虽然remember会自动保存，但提供手动保存接口。\n   */\n  save() {\n    this.network.persistSync(this.dataPath);\n    logger.info('[CognitionSystem] Manual save completed');\n  }\n  \n  /**\n   * 手动加载\n   * \n   * 虽然prime会自动加载，但提供手动加载接口。\n   */\n  load() {\n    this.network.loadSync(this.dataPath);\n    // 重置引擎，因为network变了\n    this.rememberEngine = null;\n    this.recallEngine = null;\n    logger.info('[CognitionSystem] Manual load completed');\n  }\n}\n\nmodule.exports = CognitionSystem;","/**\n * 认知系统核心结构（极简版）\n * \n * 三个基础结构：\n * - Cue: 认知网络的节点，自管理连接\n * - Network: 所有 Cue 的容器\n * - Mind: 以某个 Cue 为中心的激活子图\n * \n * 设计原则：\n * - 只定义数据结构，不定义算法\n * - Cue 管理自己的连接（去中心化）\n * - 不存储原始内容（让大模型理解）\n */\n\nconst Cue = require('./Cue');\nconst Network = require('./Network');\nconst Mind = require('./Mind');\nconst Remember = require('./Remember');\nconst Recall = require('./Recall');\nconst Prime = require('./Prime');\nconst WeightContext = require('./WeightContext');\nconst ActivationContext = require('./ActivationContext');\nconst CognitionSystem = require('./CognitionSystem');\nconst { WeightStrategy, SimpleWeightStrategy, TimeBasedWeightStrategy } = require('./WeightStrategy');\nconst { ActivationStrategy, HippocampalActivationStrategy } = require('./ActivationStrategy');\n\nmodule.exports = {\n  // 核心数据结构\n  Cue,\n  Network,\n  Mind,\n  WeightContext,\n  ActivationContext,\n  \n  // 操作类\n  Remember,\n  Recall,\n  Prime,\n  \n  // 权重策略\n  WeightStrategy,\n  SimpleWeightStrategy,\n  TimeBasedWeightStrategy,\n  \n  // 激活策略\n  ActivationStrategy,\n  HippocampalActivationStrategy,\n  \n  // 系统\n  CognitionSystem\n};"],"mappings":";;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA,yBAAAA,UAAAC,SAAA;AAAA;AAAA;AAmDA,QAAMC,OAAN,MAAM,KAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUR,YAAY,MAAM;AAWhB,aAAK,OAAO;AAiBZ,aAAK,cAAc,oBAAI,IAAI;AAAA,MAC7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWA,eAAe;AACb,eAAO,KAAK,YAAY;AAAA,MAC1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWA,yBAAyB;AACvB,YAAI,KAAK,YAAY,SAAS,EAAG,QAAO;AAExC,YAAI,YAAY;AAChB,YAAI,gBAAgB;AAEpB,mBAAW,CAAC,MAAM,MAAM,KAAK,KAAK,aAAa;AAC7C,cAAI,SAAS,WAAW;AACtB,wBAAY;AACZ,4BAAgB;AAAA,UAClB;AAAA,QACF;AAEA,eAAO,EAAE,MAAM,eAAe,QAAQ,UAAU;AAAA,MAClD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,qBAAqB,QAAQ,UAAU;AACrC,eAAO,MAAM,KAAK,KAAK,YAAY,QAAQ,CAAC,EACzC,IAAI,CAAC,CAAC,MAAM,MAAM,OAAO,EAAE,MAAM,OAAO,EAAE,EAC1C,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,EAAE,MAAM,EAClC,MAAM,GAAG,KAAK;AAAA,MACnB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,SAAS;AACP,eAAO;AAAA,UACL,MAAM,KAAK;AAAA,UACX,aAAa,MAAM,KAAK,KAAK,YAAY,QAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,QAAQ,MAAM,OAAO;AAAA,YAC7E;AAAA,YACA;AAAA,UACF,EAAE;AAAA,QACJ;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,OAAO,SAAS,MAAM;AACpB,cAAM,MAAM,IAAI,KAAI,KAAK,IAAI;AAC7B,YAAI,KAAK,aAAa;AACpB,qBAAW,QAAQ,KAAK,aAAa;AACnC,gBAAI,YAAY,IAAI,KAAK,QAAQ,KAAK,MAAM;AAAA,UAC9C;AAAA,QACF;AACA,eAAO;AAAA,MACT;AAAA,IACF;AAEA,IAAAD,QAAO,UAAUC;AAAA;AAAA;;;AC/KjB;AAAA,kCAAAC,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAMC,OAAM;AACZ,QAAM,SAAS,QAAQ,iBAAiB;AA2CxC,QAAM,eAAN,MAAM,sBAAqBA,KAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAM7B,YAAY,MAAM;AAChB,cAAM,IAAI;AAYV,aAAK,kBAAkB;AAAA,MACzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,qBAAqB;AACnB,aAAK;AACL,eAAO,MAAM,wCAAwC;AAAA,UACnD,MAAM,KAAK;AAAA,UACX,cAAc,KAAK;AAAA,QACrB,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,eAAe;AACb,eAAO,KAAK;AAAA,MACd;AAAA;AAAA;AAAA;AAAA,MAKA,iBAAiB;AACf,aAAK,kBAAkB;AACvB,eAAO,MAAM,kCAAkC,EAAE,MAAM,KAAK,KAAK,CAAC;AAAA,MACpE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,SAAS;AACP,eAAO;AAAA,UACL,GAAG,MAAM,OAAO;AAAA,UAChB,iBAAiB,KAAK;AAAA,QACxB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,OAAO,SAAS,MAAM;AACpB,cAAM,UAAU,IAAI,cAAa,KAAK,IAAI;AAG1C,YAAI,KAAK,aAAa;AACpB,qBAAW,QAAQ,KAAK,aAAa;AACnC,oBAAQ,YAAY,IAAI,KAAK,QAAQ,KAAK,MAAM;AAAA,UAClD;AAAA,QACF;AAGA,gBAAQ,kBAAkB,KAAK,mBAAmB;AAElD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,eAAe;AACb,eAAO;AAAA,UACL,MAAM,KAAK;AAAA,UACX,WAAW,KAAK,aAAa;AAAA,UAC7B,iBAAiB,KAAK;AAAA,UACtB,qBAAqB,KAAK,uBAAuB;AAAA,QACnD;AAAA,MACF;AAAA,IACF;AAEA,IAAAD,QAAO,UAAU;AAAA;AAAA;;;ACpJjB;AAAA,6BAAAE,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AACxC,QAAM,KAAK,QAAQ,IAAI;AACvB,QAAM,OAAO,QAAQ,MAAM;AA2D3B,QAAMC,WAAN,MAAc;AAAA,MACZ,cAAc;AAUZ,aAAK,OAAO,oBAAI,IAAI;AAEpB,eAAO,MAAM,qCAAqC;AAAA,MACpD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWA,eAAe,MAAM;AACnB,YAAI,CAAC,KAAK,KAAK,IAAI,IAAI,GAAG;AACxB,gBAAM,eAAe;AACrB,gBAAM,MAAM,IAAI,aAAa,IAAI;AACjC,eAAK,KAAK,IAAI,MAAM,GAAG;AACvB,iBAAO,MAAM,sCAAsC,EAAE,KAAK,CAAC;AAAA,QAC7D;AACA,eAAO,KAAK,KAAK,IAAI,IAAI;AAAA,MAC3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,OAAO,MAAM;AACX,eAAO,KAAK,KAAK,IAAI,IAAI;AAAA,MAC3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,OAAO,MAAM;AACX,eAAO,KAAK,KAAK,IAAI,IAAI;AAAA,MAC3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,OAAO;AACL,eAAO,KAAK,KAAK;AAAA,MACnB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,qBAAqB;AACnB,cAAM,YAAY,oBAAI,IAAI;AAG1B,mBAAW,QAAQ,KAAK,KAAK,KAAK,GAAG;AACnC,oBAAU,IAAI,MAAM,CAAC;AAAA,QACvB;AAGA,mBAAW,CAAC,YAAY,SAAS,KAAK,KAAK,MAAM;AAC/C,qBAAW,cAAc,UAAU,YAAY,KAAK,GAAG;AACrD,kBAAM,gBAAgB,UAAU,IAAI,UAAU,KAAK;AACnD,sBAAU,IAAI,YAAY,gBAAgB,CAAC;AAAA,UAC7C;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,qBAAqB;AACnB,cAAM,YAAY,oBAAI,IAAI;AAG1B,mBAAW,CAAC,YAAY,SAAS,KAAK,KAAK,MAAM;AAC/C,qBAAW,CAAC,YAAY,MAAM,KAAK,UAAU,aAAa;AACxD,kBAAM,gBAAgB,UAAU,IAAI,UAAU,KAAK;AACnD,sBAAU,IAAI,YAAY,gBAAgB,MAAM;AAAA,UAClD;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,gBAAgB;AACd,YAAI,mBAAmB;AACvB,YAAI,eAAe;AACnB,YAAI,UAAU;AACd,YAAI,gBAAgB;AAEpB,mBAAW,CAAC,MAAM,GAAG,KAAK,KAAK,MAAM;AACnC,gBAAM,YAAY,IAAI,YAAY;AAClC,8BAAoB;AAEpB,cAAI,cAAc,GAAG;AACnB;AAAA,UACF;AAEA,cAAI,YAAY,cAAc;AAC5B,2BAAe;AACf,sBAAU;AAAA,UACZ;AAAA,QACF;AAEA,cAAM,YAAY,KAAK,mBAAmB;AAC1C,YAAI,cAAc;AAClB,YAAI,WAAW;AAEf,mBAAW,CAAC,MAAM,QAAQ,KAAK,WAAW;AACxC,cAAI,WAAW,aAAa;AAC1B,0BAAc;AACd,uBAAW;AAAA,UACb;AAAA,QACF;AAEA,eAAO;AAAA,UACL,WAAW,KAAK,KAAK;AAAA,UACrB;AAAA,UACA,kBAAkB,KAAK,KAAK,OAAO,IAAI,mBAAmB,KAAK,KAAK,OAAO;AAAA,UAC3E;AAAA,UACA;AAAA;AAAA,UACA;AAAA,UACA;AAAA;AAAA,UACA;AAAA;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAaA,MAAM,QAAQ,UAAU;AACtB,YAAI;AACF,gBAAMC,MAAK,QAAQ,IAAI,EAAE;AACzB,gBAAMC,QAAO,QAAQ,MAAM;AAG3B,gBAAM,OAAO;AAAA,YACX,SAAS;AAAA,YACT,WAAW,KAAK,IAAI;AAAA,YACpB,MAAM,CAAC;AAAA,UACT;AAGA,qBAAW,CAAC,MAAM,GAAG,KAAK,KAAK,MAAM;AACnC,iBAAK,KAAK,IAAI,IAAI,IAAI,OAAO;AAAA,UAC/B;AAGA,gBAAM,MAAMA,MAAK,QAAQ,QAAQ;AACjC,gBAAMD,IAAG,MAAM,KAAK,EAAE,WAAW,KAAK,CAAC;AAGvC,gBAAMA,IAAG,UAAU,UAAU,KAAK,UAAU,MAAM,MAAM,CAAC,GAAG,MAAM;AAElE,iBAAO,KAAK,+BAA+B;AAAA,YACzC,MAAM;AAAA,YACN,MAAM,KAAK,KAAK;AAAA,YAChB,MAAM,KAAK,UAAU,IAAI,EAAE;AAAA,UAC7B,CAAC;AAAA,QACH,SAAS,OAAO;AACd,iBAAO,MAAM,+BAA+B;AAAA,YAC1C,MAAM;AAAA,YACN,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,MAAM,KAAK,UAAU;AACnB,YAAI;AACF,gBAAMA,MAAK,QAAQ,IAAI,EAAE;AACzB,gBAAM,eAAe;AAGrB,gBAAM,UAAU,MAAMA,IAAG,SAAS,UAAU,MAAM;AAClD,gBAAM,OAAO,KAAK,MAAM,OAAO;AAG/B,cAAI,KAAK,YAAY,OAAO;AAC1B,mBAAO,KAAK,8BAA8B;AAAA,cACxC,UAAU;AAAA,cACV,QAAQ,KAAK;AAAA,YACf,CAAC;AAAA,UACH;AAGA,eAAK,KAAK,MAAM;AAGhB,qBAAW,CAAC,MAAM,OAAO,KAAK,OAAO,QAAQ,KAAK,IAAI,GAAG;AACvD,kBAAM,MAAM,aAAa,SAAS,OAAO;AACzC,iBAAK,KAAK,IAAI,MAAM,GAAG;AAAA,UACzB;AAEA,iBAAO,KAAK,8BAA8B;AAAA,YACxC,MAAM;AAAA,YACN,MAAM,KAAK,KAAK;AAAA,YAChB,WAAW,IAAI,KAAK,KAAK,SAAS,EAAE,YAAY;AAAA,UAClD,CAAC;AAAA,QACH,SAAS,OAAO;AACd,iBAAO,MAAM,4BAA4B;AAAA,YACvC,MAAM;AAAA,YACN,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,YAAY,UAAU;AACpB,YAAI;AAEF,gBAAM,OAAO;AAAA,YACX,SAAS;AAAA,YACT,WAAW,KAAK,IAAI;AAAA,YACpB,MAAM,CAAC;AAAA,UACT;AAGA,qBAAW,CAAC,MAAM,GAAG,KAAK,KAAK,MAAM;AACnC,iBAAK,KAAK,IAAI,IAAI,IAAI,OAAO;AAAA,UAC/B;AAGA,gBAAM,MAAM,KAAK,QAAQ,QAAQ;AACjC,aAAG,UAAU,KAAK,EAAE,WAAW,KAAK,CAAC;AAGrC,aAAG,cAAc,UAAU,KAAK,UAAU,MAAM,MAAM,CAAC,GAAG,MAAM;AAEhE,iBAAO,MAAM,sCAAsC;AAAA,YACjD,MAAM;AAAA,YACN,MAAM,KAAK,KAAK;AAAA,UAClB,CAAC;AAAA,QACH,SAAS,OAAO;AACd,iBAAO,MAAM,sCAAsC;AAAA,YACjD,MAAM;AAAA,YACN,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,SAAS,UAAU;AACjB,YAAI;AACF,gBAAM,eAAe;AAGrB,gBAAM,UAAU,GAAG,aAAa,UAAU,MAAM;AAChD,gBAAM,OAAO,KAAK,MAAM,OAAO;AAG/B,cAAI,KAAK,YAAY,OAAO;AAC1B,mBAAO,KAAK,8BAA8B;AAAA,cACxC,UAAU;AAAA,cACV,QAAQ,KAAK;AAAA,YACf,CAAC;AAAA,UACH;AAGA,eAAK,KAAK,MAAM;AAGhB,qBAAW,CAAC,MAAM,OAAO,KAAK,OAAO,QAAQ,KAAK,IAAI,GAAG;AACvD,kBAAM,MAAM,aAAa,SAAS,OAAO;AACzC,iBAAK,KAAK,IAAI,MAAM,GAAG;AAAA,UACzB;AAEA,iBAAO,MAAM,qCAAqC;AAAA,YAChD,MAAM;AAAA,YACN,MAAM,KAAK,KAAK;AAAA,UAClB,CAAC;AAAA,QACH,SAAS,OAAO;AACd,iBAAO,MAAM,mCAAmC;AAAA,YAC9C,MAAM;AAAA,YACN,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,sBAAsB,eAAe;AACnC,YAAI,CAAC,iBAAiB,cAAc,SAAS,GAAG;AAC9C;AAAA,QACF;AAEA,YAAI,eAAe;AACnB,mBAAW,QAAQ,eAAe;AAChC,gBAAM,MAAM,KAAK,KAAK,IAAI,IAAI;AAC9B,cAAI,OAAO,OAAO,IAAI,uBAAuB,YAAY;AACvD,gBAAI,mBAAmB;AACvB;AAAA,UACF;AAAA,QACF;AAEA,eAAO,MAAM,wCAAwC;AAAA,UACnD,WAAW,cAAc;AAAA,UACzB,SAAS;AAAA,QACX,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,yBAAyB;AACvB,YAAI,iBAAiB;AACrB,YAAI,eAAe;AACnB,YAAI,mBAAmB;AACvB,cAAM,wBAAwB,oBAAI,IAAI;AAEtC,mBAAW,CAAC,MAAM,GAAG,KAAK,KAAK,MAAM;AACnC,gBAAM,YAAY,IAAI,mBAAmB;AACzC,4BAAkB;AAElB,cAAI,YAAY,cAAc;AAC5B,2BAAe;AACf,+BAAmB;AAAA,UACrB;AAGA,gBAAM,SAAS,KAAK,MAAM,YAAY,EAAE,IAAI;AAC5C,gCAAsB,IAAI,SAAS,sBAAsB,IAAI,MAAM,KAAK,KAAK,CAAC;AAAA,QAChF;AAEA,eAAO;AAAA,UACL,cAAc;AAAA,UACd,kBAAkB,KAAK,KAAK,OAAO,IAAI,iBAAiB,KAAK,KAAK,OAAO;AAAA,UACzE;AAAA,UACA;AAAA,UACA,cAAc,MAAM,KAAK,sBAAsB,QAAQ,CAAC,EACrD,KAAK,CAAC,GAAG,MAAM,EAAE,CAAC,IAAI,EAAE,CAAC,CAAC,EAC1B,IAAI,CAAC,CAAC,QAAQ,KAAK,OAAO,EAAE,OAAO,GAAG,MAAM,IAAI,SAAO,CAAC,IAAI,MAAM,EAAE;AAAA,QACzE;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,QAAQ;AACN,cAAM,eAAe,KAAK,KAAK;AAC/B,aAAK,KAAK,MAAM;AAChB,eAAO,KAAK,qBAAqB,EAAE,aAAa,CAAC;AAAA,MACnD;AAAA,IACF;AAEA,IAAAF,QAAO,UAAUC;AAAA;AAAA;;;AC9djB;AAAA,0BAAAG,UAAAC,SAAA;AAAA;AAAA;AA0DA,QAAMC,QAAN,MAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAMT,YAAY,QAAQ;AAUlB,aAAK,SAAS;AAiBd,aAAK,gBAAgB,oBAAI,IAAI;AAa7B,aAAK,cAAc,CAAC;AAUpB,aAAK,UAAU,CAAC;AAUhB,aAAK,SAAS,oBAAI,IAAI;AAGtB,YAAI,QAAQ;AACV,eAAK,cAAc,IAAI,OAAO,IAAI;AAClC,eAAK,OAAO,IAAI,OAAO,MAAM,CAAC;AAAA,QAChC;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,gBAAgB,MAAM,QAAQ,GAAG;AAC/B,aAAK,cAAc,IAAI,IAAI;AAC3B,YAAI,CAAC,KAAK,OAAO,IAAI,IAAI,KAAK,KAAK,OAAO,IAAI,IAAI,IAAI,OAAO;AAC3D,eAAK,OAAO,IAAI,MAAM,KAAK;AAAA,QAC7B;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,cAAc,MAAM,IAAI,QAAQ;AAC9B,aAAK,YAAY,KAAK,EAAE,MAAM,IAAI,OAAO,CAAC;AAE1C,aAAK,cAAc,IAAI,IAAI;AAC3B,aAAK,cAAc,IAAI,EAAE;AAAA,MAC3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,OAAO;AACL,eAAO,KAAK,cAAc;AAAA,MAC5B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,kBAAkB;AAChB,eAAO,KAAK,YAAY;AAAA,MAC1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,UAAU;AACR,eAAO,KAAK,cAAc,SAAS;AAAA,MACrC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,uBAAuB;AACrB,eAAO,CAAC,GAAG,KAAK,WAAW,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,EAAE,MAAM;AAAA,MACjE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,uBAAuB,MAAM;AAC3B,eAAO,KAAK,YAAY,OAAO,UAAQ,KAAK,SAAS,IAAI;AAAA,MAC3D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,uBAAuB,MAAM;AAC3B,eAAO,KAAK,YAAY,OAAO,UAAQ,KAAK,OAAO,IAAI;AAAA,MACzD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYA,SAAS;AACP,eAAO;AAAA,UACL,QAAQ,KAAK,SAAS,KAAK,OAAO,OAAO;AAAA,UACzC,SAAS,KAAK,QAAQ,IAAI,OAAK,EAAE,IAAI;AAAA,UACrC,eAAe,MAAM,KAAK,KAAK,aAAa;AAAA,UAC5C,aAAa,KAAK;AAAA,UAClB,QAAQ,MAAM,KAAK,KAAK,OAAO,QAAQ,CAAC,EAAE,IAAI,CAAC,CAAC,MAAM,KAAK,OAAO,EAAE,MAAM,MAAM,EAAE;AAAA,UAClF,YAAY;AAAA,YACV,WAAW,KAAK,cAAc;AAAA,YAC9B,WAAW,KAAK,YAAY;AAAA,YAC5B,UAAU,KAAK,IAAI,GAAG,KAAK,OAAO,OAAO,GAAG,CAAC;AAAA,UAC/C;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,YAAY;AACV,YAAI,CAAC,KAAK,UAAU,KAAK,cAAc,SAAS,GAAG;AACjD,iBAAO;AAAA,QACT;AAGA,cAAM,OAAO,KAAK,UAAU;AAG5B,YAAI,UAAU;AACd,mBAAW,WAAW,KAAK,OAAO,IAAI;AAAA;AAGtC,cAAM,cAAc,CAAC,QAAQ,WAAW;AACtC,gBAAM,WAAW,KAAK,IAAI,MAAM,KAAK,CAAC;AACtC,qBAAW,SAAS,UAAU;AAC5B,uBAAW,IAAI,OAAO,MAAM,IAAI,QAAQ;AACxC,wBAAY,OAAO,SAAS,CAAC;AAAA,UAC/B;AAAA,QACF;AAEA,oBAAY,KAAK,OAAO,MAAM,CAAC;AAE/B,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,YAAY;AACV,cAAM,OAAO,oBAAI,IAAI;AACrB,cAAM,UAAU,oBAAI,IAAI;AAGxB,mBAAW,QAAQ,KAAK,aAAa;AACnC,cAAI,CAAC,KAAK,IAAI,KAAK,IAAI,GAAG;AACxB,iBAAK,IAAI,KAAK,MAAM,CAAC,CAAC;AAAA,UACxB;AAEA,cAAI,CAAC,QAAQ,IAAI,GAAG,KAAK,IAAI,KAAK,KAAK,EAAE,EAAE,GAAG;AAC5C,iBAAK,IAAI,KAAK,IAAI,EAAE,KAAK,KAAK,EAAE;AAChC,oBAAQ,IAAI,GAAG,KAAK,IAAI,KAAK,KAAK,EAAE,EAAE;AAAA,UACxC;AAAA,QACF;AAGA,mBAAW,CAAC,QAAQ,QAAQ,KAAK,MAAM;AAErC,gBAAM,qBAAqB,SAAS,IAAI,WAAS;AAC/C,kBAAM,OAAO,KAAK,YAAY,KAAK,OAAK,EAAE,SAAS,UAAU,EAAE,OAAO,KAAK;AAC3E,mBAAO,EAAE,OAAO,QAAQ,OAAO,KAAK,SAAS,EAAE;AAAA,UACjD,CAAC;AAED,6BAAmB,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,EAAE,MAAM;AAErD,eAAK,IAAI,QAAQ,mBAAmB,IAAI,UAAQ,KAAK,KAAK,CAAC;AAAA,QAC7D;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,MAAM,WAAW;AAEf,mBAAW,OAAO,UAAU,eAAe;AACzC,eAAK,cAAc,IAAI,GAAG;AAAA,QAC5B;AAGA,cAAM,gBAAgB,IAAI;AAAA,UACxB,KAAK,YAAY,IAAI,OAAK,GAAG,EAAE,IAAI,KAAK,EAAE,EAAE,EAAE;AAAA,QAChD;AAEA,mBAAW,QAAQ,UAAU,aAAa;AACxC,gBAAM,MAAM,GAAG,KAAK,IAAI,KAAK,KAAK,EAAE;AACpC,cAAI,CAAC,cAAc,IAAI,GAAG,GAAG;AAC3B,iBAAK,YAAY,KAAK,IAAI;AAAA,UAC5B;AAAA,QACF;AAGA,mBAAW,CAAC,MAAM,KAAK,KAAK,UAAU,QAAQ;AAC5C,cAAI,CAAC,KAAK,OAAO,IAAI,IAAI,KAAK,KAAK,OAAO,IAAI,IAAI,IAAI,OAAO;AAC3D,iBAAK,OAAO,IAAI,MAAM,KAAK;AAAA,UAC7B;AAAA,QACF;AAGA,YAAI,UAAU,QAAQ;AACpB,eAAK,QAAQ,KAAK,UAAU,MAAM;AAAA,QACpC;AAAA,MACF;AAAA,IACF;AAEA,IAAAD,QAAO,UAAUC;AAAA;AAAA;;;AC/VjB;AAAA,4BAAAC,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AAuCxC,QAAM,SAAN,MAAM,QAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUX,YAAY,EAAE,SAAS,QAAQ,UAAU,UAAU,GAAG;AAEpD,YAAI,CAAC,SAAS;AACZ,gBAAM,IAAI,MAAM,yBAAyB;AAAA,QAC3C;AACA,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,MAAM,wBAAwB;AAAA,QAC1C;AACA,YAAI,aAAa,UAAa,aAAa,MAAM;AAC/C,gBAAM,IAAI,MAAM,0BAA0B;AAAA,QAC5C;AAOA,aAAK,UAAU;AAOf,aAAK,SAAS,KAAK,iBAAiB,MAAM;AAO1C,aAAK,WAAW,KAAK,kBAAkB,QAAQ;AAO/C,aAAK,YAAY,aAAa,KAAK,IAAI;AAOvC,aAAK,KAAK,GAAG,KAAK,SAAS,IAAI,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,OAAO,GAAG,CAAC,CAAC;AAEtE,eAAO,MAAM,+BAA+B;AAAA,UAC1C,cAAc,KAAK,OAAO;AAAA,UAC1B,UAAU,KAAK;AAAA,UACf,WAAW,IAAI,KAAK,KAAK,SAAS,EAAE,YAAY;AAAA,QAClD,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,iBAAiB,QAAQ;AACvB,YAAI,MAAM,QAAQ,MAAM,GAAG;AACzB,iBAAO,OAAO,OAAO,UAAQ,QAAQ,OAAO,SAAS,QAAQ;AAAA,QAC/D;AAEA,YAAI,OAAO,WAAW,UAAU;AAE9B,iBAAO,OACJ,MAAM,IAAI,EACV,IAAI,OAAK,EAAE,KAAK,CAAC,EACjB,OAAO,OAAO;AAAA,QACnB;AAEA,cAAM,IAAI,MAAM,kCAAkC;AAAA,MACpD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,kBAAkB,UAAU;AAC1B,cAAM,MAAM,OAAO,QAAQ;AAC3B,YAAI,MAAM,GAAG,GAAG;AACd,gBAAM,IAAI,MAAM,2BAA2B;AAAA,QAC7C;AACA,YAAI,MAAM,KAAK,MAAM,GAAG;AACtB,gBAAM,IAAI,MAAM,kCAAkC;AAAA,QACpD;AACA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,IAAI,SAAS;AACX,eAAO,KAAK,OAAO;AAAA,MACrB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,UAAU;AACR,eAAO,KAAK,OAAO,UAAU;AAAA,MAC/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,WAAW,YAAY,GAAG;AACxB,cAAM,UAAU,KAAK,OAAO,MAAM,GAAG,SAAS,EAAE,KAAK,MAAM;AAC3D,eAAO,KAAK,OAAO,SAAS,YAAY,GAAG,OAAO,QAAQ;AAAA,MAC5D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,SAAS;AACP,eAAO;AAAA,UACL,IAAI,KAAK;AAAA,UACT,SAAS,KAAK;AAAA,UACd,QAAQ,KAAK;AAAA,UACb,UAAU,KAAK;AAAA,UACf,WAAW,KAAK;AAAA,QAClB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,OAAO,SAAS,MAAM;AACpB,eAAO,IAAI,QAAO,IAAI;AAAA,MACxB;AAAA,IACF;AAEA,IAAAA,QAAO,UAAU;AAAA;AAAA;;;AC9MjB;AAAA,mCAAAC,UAAAC,SAAA;AAAA;AAAA;AAwDA,QAAMC,iBAAN,MAAoB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWlB,YAAY,MAAM;AAUhB,aAAK,YAAY,KAAK;AAUtB,aAAK,aAAa,KAAK;AAYvB,aAAK,WAAW,KAAK;AAarB,aAAK,YAAY,KAAK,aAAa,KAAK,IAAI;AAY5C,aAAK,kBAAkB,KAAK,YAAY,KAAK,UAAU,YAAY,OAAO;AAe1E,aAAK,SAAS,KAAK,UAAU;AAU7B,aAAK,WAAW,KAAK,SAAS,KAAK,OAAO,WAAW;AAAA,MACvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,gBAAgB;AACd,eAAO,KAAK,YAAY,KAAK,UAAU,OAAO;AAAA,MAChD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,WAAW;AACT,cAAM,aAAa,KAAK,cAAc;AACtC,eAAO,iBAAiB,UAAU,KAAK,KAAK,UAAU,SAAS,KAAK,QAAQ,YAAY,KAAK,eAAe;AAAA,MAC9G;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,SAAS;AACP,eAAO;AAAA,UACL,YAAY,KAAK,cAAc;AAAA,UAC/B,YAAY,KAAK;AAAA,UACjB,UAAU,KAAK;AAAA,UACf,WAAW,KAAK;AAAA,UAChB,iBAAiB,KAAK;AAAA,UACtB,UAAU,KAAK;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAEA,IAAAD,QAAO,UAAUC;AAAA;AAAA;;;AClMjB;AAAA,8BAAAC,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AAgExC,QAAMC,YAAN,MAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOb,YAAY,SAAS,UAAU,CAAC,GAAG;AAKjC,aAAK,UAAU;AAMf,aAAK,WAAW,QAAQ,YAAY;AAEpC,YAAI,KAAK,UAAU;AACjB,iBAAO,MAAM,wCAAwC;AAAA,YACnD,UAAU,KAAK,SAAS,YAAY;AAAA,UACtC,CAAC;AAAA,QACH,OAAO;AACL,iBAAO,KAAK,iCAAiC;AAAA,QAC/C;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAeA,QAAQ,QAAQ,WAAW,MAAM;AAE/B,cAAM,SAAS;AACf,YAAI,CAAC,UAAU,EAAE,kBAAkB,SAAS;AAC1C,iBAAO,KAAK,sCAAsC,EAAE,OAAO,CAAC;AAC5D,iBAAO;AAAA,YACL,WAAW;AAAA,YACX,aAAa,CAAC;AAAA,UAChB;AAAA,QACF;AAEA,YAAI,CAAC,OAAO,QAAQ,GAAG;AACrB,iBAAO,MAAM,gEAAgE;AAAA,YAC3E,QAAQ,OAAO;AAAA,UACjB,CAAC;AACD,iBAAO;AAAA,YACL,WAAW,OAAO;AAAA,YAClB,aAAa,CAAC;AAAA,UAChB;AAAA,QACF;AAEA,cAAM,EAAE,QAAQ,UAAU,UAAU,IAAI;AAExC,eAAO,MAAM,gCAAgC;AAAA,UAC3C,QAAQ,OAAO;AAAA,UACf;AAAA,UACA,SAAS,OAAO,WAAW;AAAA,QAC7B,CAAC;AAGD,eAAO,MAAM,6CAA6C;AAC1D,cAAM,cAAc,CAAC;AACrB,mBAAW,QAAQ,QAAQ;AAEzB,cAAI,CAAC,KAAK,QAAQ,KAAK,IAAI,IAAI,GAAG;AAChC,wBAAY,KAAK,IAAI;AAAA,UACvB;AACA,eAAK,QAAQ,eAAe,IAAI;AAAA,QAClC;AAEA,YAAI,YAAY,SAAS,GAAG;AAC1B,iBAAO,MAAM,+BAA+B;AAAA,YAC1C,OAAO,YAAY;AAAA,YACnB,MAAM,YAAY,MAAM,GAAG,EAAE;AAAA;AAAA,UAC/B,CAAC;AAAA,QACH;AAGA,eAAO,MAAM,mDAAmD;AAChE,cAAMC,iBAAgB;AACtB,cAAM,cAAc,CAAC;AAIrB,iBAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAC1C,gBAAM,aAAa,OAAO,CAAC;AAC3B,gBAAM,aAAa,OAAO,IAAI,CAAC;AAC/B,gBAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,UAAU;AAGlD,gBAAM,iBAAiB,UAAU,YAAY,IAAI,UAAU;AAC3D,cAAI,CAAC,gBAAgB;AAEnB,sBAAU,YAAY,IAAI,YAAY,CAAC;AAAA,UACzC;AAAA,QACF;AAGA,eAAO,MAAM,wDAAwD;AACrE,iBAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAC1C,gBAAM,aAAa,OAAO,CAAC;AAC3B,gBAAM,aAAa,OAAO,IAAI,CAAC;AAC/B,gBAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,UAAU;AAGlD,gBAAM,UAAU,IAAIA,eAAc;AAAA,YAChC;AAAA,YACA;AAAA,YACA,UAAU;AAAA,YACV;AAAA,YACA;AAAA;AAAA,UACF,CAAC;AAGD,gBAAM,SAAS,KAAK,SAAS,UAAU,OAAO;AAE9C,iBAAO,MAAM,iCAAiC;AAAA,YAC5C,MAAM;AAAA,YACN,IAAI;AAAA,YACJ,UAAU;AAAA,YACV,WAAW,QAAQ;AAAA,YACnB;AAAA,UACF,CAAC;AAGD,oBAAU,YAAY,IAAI,YAAY,MAAM;AAG5C,sBAAY,KAAK;AAAA,YACf,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR;AAAA,YACA,UAAU;AAAA,UACZ,CAAC;AAAA,QACH;AAEA,eAAO,KAAK,4CAA4C;AAAA,UACtD,OAAO,OAAO;AAAA,UACd,aAAa,YAAY;AAAA,UACzB,WAAW,IAAI,KAAK,SAAS,EAAE,YAAY;AAAA,QAC7C,CAAC;AAGD,cAAM,iBAAiB,YAAY,OAAO;AAC1C,YAAI,gBAAgB;AAClB,qBAAW,QAAQ,QAAQ;AACzB,kBAAM,MAAM,KAAK,QAAQ,KAAK,IAAI,IAAI;AACtC,gBAAI,KAAK;AACP,kBAAI,CAAC,IAAI,UAAU;AACjB,oBAAI,WAAW,oBAAI,IAAI;AAAA,cACzB;AACA,kBAAI,SAAS,IAAI,cAAc;AAE/B,qBAAO,MAAM,qCAAqC;AAAA,gBAChD,KAAK;AAAA,gBACL,UAAU;AAAA,gBACV,iBAAiB,IAAI,SAAS;AAAA,cAChC,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AAEA,eAAO;AAAA,UACL,WAAW,OAAO;AAAA,UAClB;AAAA,UACA;AAAA,UACA,UAAU;AAAA,QACZ;AAAA,MACF;AAAA,IACF;AAEA,IAAAF,QAAO,UAAUC;AAAA;AAAA;;;ACvPjB;AAAA,wCAAAE,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AA6BxC,QAAMC,sBAAN,MAAyB;AAAA,MACvB,YAAY,UAAU,CAAC,GAAG;AAKxB,aAAK,OAAO;AAMZ,aAAK,UAAU;AAAA,MACjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYA,SAAS,SAAS;AAChB,cAAM,IAAI,MAAM,mDAAmD;AAAA,MACrE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,eAAe,SAAS;AACtB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,WAAW,SAAS;AAAA,MAEpB;AAAA,IACF;AAmCA,QAAMC,iCAAN,cAA4CD,oBAAmB;AAAA,MAC7D,YAAY,UAAU,CAAC,GAAG;AACxB,cAAM,OAAO;AAMb,aAAK,OAAO;AAOZ,aAAK,kBAAkB,QAAQ,mBAAmB;AAOlD,aAAK,gBAAgB,QAAQ,iBAAiB;AAO9C,aAAK,mBAAmB,QAAQ,oBAAoB;AAOpD,aAAK,YAAY,QAAQ,aAAa;AAOtC,aAAK,aAAa,QAAQ,cAAc;AAOxC,aAAK,iBAAiB,QAAQ,kBAAkB;AAMhD,aAAK,iBAAiB,QAAQ,kBAAkB;AAEhD,eAAO,MAAM,+CAA+C;AAAA,UAC1D,iBAAiB,KAAK;AAAA,UACtB,eAAe,KAAK;AAAA,UACpB,WAAW,KAAK;AAAA,QAClB,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,SAAS,SAAS;AAtLpB;AAwLI,YAAI,QAAQ,gBAAgB,KAAK,iBAAiB;AAChD,iBAAO,MAAM,0DAA0D;AAAA,YACrE,OAAM,aAAQ,cAAR,mBAAmB;AAAA,YACzB,QAAQ,QAAQ;AAAA,YAChB,WAAW,KAAK;AAAA,UAClB,CAAC;AACD,iBAAO,EAAE,gBAAgB,OAAO,OAAO,CAAC,EAAE;AAAA,QAC5C;AAEA,YAAI,CAAC,QAAQ,aAAa,CAAC,QAAQ,UAAU,aAAa;AACxD,iBAAO,EAAE,gBAAgB,OAAO,OAAO,CAAC,EAAE;AAAA,QAC5C;AAGA,YAAI,QAAQ,MAAM,KAAK,QAAQ,UAAU,YAAY,QAAQ,CAAC,EAC3D,IAAI,CAAC,CAAC,YAAY,MAAM,OAAO;AAAA,UAC9B;AAAA,UACA;AAAA,UACA,WAAW,QAAQ,mBAAmB,UAAU;AAAA,QAClD,EAAE;AAGJ,YAAI,KAAK,kBAAkB,OAAO,KAAK,eAAe,2BAA2B,YAAY;AAC3F,kBAAQ,KAAK,eAAe,uBAAuB,KAAK;AACxD,iBAAO,MAAM,yEAAyE;AAAA,YACpF,UAAU,KAAK,eAAe,YAAY;AAAA,YAC1C,WAAW,MAAM;AAAA,UACnB,CAAC;AAAA,QACH;AAGA,cAAM,iBAAiB,MAAM,IAAI,UAAQ;AAEvC,gBAAM,wBAAwB,KAAK,eAAgB,KAAK,SAAS,MAAM,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,QAAQ,CAAC;AAG3G,gBAAM,YAAY,IAAI,KAAK,IAAI,IAAI,KAAK,SAAS,IAAI,KAAK;AAG1D,gBAAM,oBAAoB,QAAQ,gBACT,wBACA,KAAK,gBACL;AAGzB,gBAAM,aAAa,IAAK,KAAK,mBAAmB,QAAQ,eAAe,OAAO;AAC9E,gBAAM,cAAc,oBAAoB;AAExC,iBAAO;AAAA,YACL,YAAY,KAAK;AAAA,YACjB,QAAQ,KAAK;AAAA,YACb,QAAQ;AAAA,YACR,WAAW,KAAK;AAAA,YAChB,aAAa;AAAA,YACb,iBAAiB,KAAK,mBAAmB;AAAA,YACzC,YAAY,eAAe,KAAK;AAAA,UAClC;AAAA,QACF,CAAC;AAGD,cAAM,cAAc,eAAe;AAAA,UAAO,OACxC,EAAE,cAAc,CAAC,QAAQ,YAAY,EAAE,UAAU;AAAA,QACnD;AAEA,eAAO,MAAM,uDAAuD;AAAA,UAClE,QAAQ,QAAQ,UAAU;AAAA,UAC1B,cAAc,QAAQ;AAAA,UACtB,YAAY,MAAM;AAAA,UAClB,aAAa,YAAY;AAAA,UACzB,OAAO,QAAQ;AAAA,UACf,mBAAmB,CAAC,CAAC,KAAK;AAAA,QAC5B,CAAC;AAED,eAAO,EAAE,gBAAgB,MAAM,OAAO,YAAY;AAAA,MACpD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,eAAe,SAAS;AAEtB,YAAI,QAAQ,SAAS,KAAK,WAAW;AACnC,iBAAO,MAAM,sDAAsD;AAAA,YACjE,OAAO,QAAQ;AAAA,YACf,WAAW,KAAK;AAAA,UAClB,CAAC;AACD,iBAAO;AAAA,QACT;AAGA,YAAI,oBAAoB;AACxB,mBAAW,CAAC,MAAM,MAAM,KAAK,QAAQ,YAAY;AAC/C,cAAI,UAAU,KAAK,iBAAiB;AAClC,gCAAoB;AACpB;AAAA,UACF;AAAA,QACF;AAEA,YAAI,CAAC,mBAAmB;AACtB,iBAAO,MAAM,wDAAwD;AAAA,YACnE,OAAO,QAAQ;AAAA,YACf,UAAU,QAAQ,WAAW;AAAA,UAC/B,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,WAAW,SAAS;AAElB,mBAAW,CAAC,MAAM,MAAM,KAAK,QAAQ,YAAY;AAC/C,gBAAM,gBAAgB,SAAS,KAAK;AAGpC,cAAI,gBAAgB,MAAM;AACxB,oBAAQ,WAAW,OAAO,IAAI;AAAA,UAChC,OAAO;AACL,oBAAQ,WAAW,IAAI,MAAM,aAAa;AAAA,UAC5C;AAAA,QACF;AAEA,eAAO,MAAM,iDAAiD;AAAA,UAC5D,OAAO,QAAQ;AAAA,UACf,gBAAgB,QAAQ,WAAW;AAAA,UACnC,aAAa,MAAM,KAAK,QAAQ,WAAW,OAAO,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC,EAAE,QAAQ,CAAC;AAAA,QAC/F,CAAC;AAAA,MACH;AAAA,IACF;AAEA,IAAAD,QAAO,UAAU;AAAA,MACf,oBAAAC;AAAA,MACA,+BAAAC;AAAA,IACF;AAAA;AAAA;;;ACpUA;AAAA,uCAAAC,UAAAC,SAAA;AAAA;AAAA;AAkCA,QAAMC,qBAAN,MAAwB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MActB,YAAY,SAAS,CAAC,GAAG;AAKvB,aAAK,UAAU,OAAO;AAMtB,aAAK,YAAY,OAAO,aAAa;AAMrC,aAAK,QAAQ,OAAO,SAAS;AAO7B,aAAK,gBAAgB,OAAO,iBAAiB;AAO7C,aAAK,iBAAiB,OAAO,kBAAkB,oBAAI,IAAI;AAOvD,aAAK,aAAa,OAAO,cAAc,oBAAI,IAAI;AAO/C,aAAK,QAAQ,OAAO,SAAS;AAO7B,aAAK,cAAc,OAAO,eAAe,CAAC;AAM1C,aAAK,YAAY,OAAO,aAAa,KAAK,IAAI;AAAA,MAChD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,mBAAmB,YAAY;AAC7B,cAAM,YAAY,KAAK,QAAQ,OAAO,UAAU;AAChD,gBAAO,uCAAW,oBAAmB;AAAA,MACvC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,YAAY,MAAM;AAChB,eAAO,KAAK,eAAe,IAAI,IAAI;AAAA,MACrC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,cAAc,MAAM;AAClB,eAAO,KAAK,WAAW,IAAI,IAAI,KAAK;AAAA,MACtC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,cAAc,MAAM,QAAQ;AAC1B,YAAI,SAAS,GAAG;AACd,eAAK,WAAW,IAAI,MAAM,MAAM;AAAA,QAClC,OAAO;AACL,eAAK,WAAW,OAAO,IAAI;AAAA,QAC7B;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,cAAc,MAAM,aAAa;AAC/B,cAAM,UAAU,KAAK,cAAc,IAAI;AACvC,cAAM,YAAY,UAAU;AAC5B,aAAK,cAAc,MAAM,SAAS;AAClC,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,cAAc,MAAM;AAClB,aAAK,eAAe,IAAI,IAAI;AAAA,MAC9B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,iBAAiB,MAAM,IAAI,QAAQ;AACjC,aAAK,YAAY,KAAK,EAAE,MAAM,IAAI,OAAO,CAAC;AAAA,MAC5C;AAAA;AAAA;AAAA;AAAA,MAKA,iBAAiB;AACf,aAAK;AAAA,MACP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,gBAAgB;AACd,eAAO;AAAA,UACL,gBAAgB,KAAK,eAAe;AAAA,UACpC,aAAa,MAAM,KAAK,KAAK,WAAW,OAAO,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC;AAAA,UAC/E,iBAAiB,MAAM,KAAK,KAAK,WAAW,QAAQ,CAAC,EAClD,OAAO,CAAC,CAAC,GAAG,MAAM,MAAM,SAAS,GAAG,EACpC;AAAA,UACH,aAAa,KAAK,YAAY;AAAA,UAC9B,OAAO,KAAK;AAAA,QACd;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,WAAW;AACT,cAAM,QAAQ,KAAK,cAAc;AACjC,eAAO,2BAA2B,KAAK,KAAK,eAAe,MAAM,cAAc,YAAY,MAAM,YAAY,QAAQ,CAAC,CAAC;AAAA,MACzH;AAAA,IACF;AAEA,IAAAD,QAAO,UAAUC;AAAA;AAAA;;;AC/NjB;AAAA,4BAAAC,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AA6BxC,QAAMC,UAAN,MAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOX,YAAY,SAAS,UAAU,CAAC,GAAG;AAKjC,aAAK,UAAU;AAMf,aAAK,iBAAiB,QAAQ,kBAAkB;AAOhD,YAAI,QAAQ,oBAAoB;AAC9B,eAAK,qBAAqB,QAAQ;AAElC,cAAI,KAAK,kBAAkB,OAAO,KAAK,mBAAmB,sBAAsB,YAAY;AAC1F,iBAAK,mBAAmB,kBAAkB,KAAK,cAAc;AAAA,UAC/D;AAAA,QACF,OAAO;AAEL,gBAAM,EAAE,+BAAAC,+BAA8B,IAAI;AAC1C,eAAK,qBAAqB,IAAIA,+BAA8B;AAAA,YAC1D,gBAAgB,KAAK;AAAA,UACvB,CAAC;AAAA,QACH;AAEA,eAAO,MAAM,wBAAwB;AAAA,UACnC,UAAU,KAAK,mBAAmB;AAAA,UAClC,mBAAmB,CAAC,CAAC,KAAK;AAAA,QAC5B,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,QAAQ,MAAM;AACZ,eAAO,MAAM,4BAA4B,EAAE,KAAK,CAAC;AAGjD,cAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,IAAI;AAC5C,YAAI,CAAC,WAAW;AACd,iBAAO,KAAK,0BAA0B,EAAE,KAAK,CAAC;AAC9C,iBAAO;AAAA,QACT;AAEA,eAAO,MAAM,6BAA6B;AAAA,UACxC,MAAM,UAAU;AAAA,UAChB,WAAW,UAAU,YAAY;AAAA,UACjC,WAAW,UAAU,mBAAmB;AAAA,QAC1C,CAAC;AAED,cAAMC,QAAO;AACb,cAAM,OAAO,IAAIA,MAAK,SAAS;AAG/B,cAAMC,qBAAoB;AAC1B,cAAM,UAAU,IAAIA,mBAAkB;AAAA,UACpC,SAAS,KAAK;AAAA,UACd,WAAW;AAAA,UACX,YAAY,oBAAI,IAAI,CAAC,CAAC,UAAU,MAAM,CAAG,CAAC,CAAC;AAAA;AAAA,UAC3C,gBAAgB,oBAAI,IAAI,CAAC,UAAU,IAAI,CAAC;AAAA,UACxC,aAAa,CAAC;AAAA,QAChB,CAAC;AAED,cAAM,YAAY,KAAK,IAAI;AAG3B,eAAO,KAAK,mBAAmB,eAAe,OAAO,GAAG;AACtD,gBAAM,iBAAiB,oBAAI,IAAI;AAG/B,qBAAW,CAACC,OAAM,MAAM,KAAK,QAAQ,YAAY;AAC/C,kBAAM,YAAY,KAAK,QAAQ,OAAOA,KAAI;AAC1C,gBAAI,CAAC,UAAW;AAGhB,oBAAQ,YAAY;AACpB,oBAAQ,gBAAgB;AAGxB,kBAAM,EAAE,gBAAgB,MAAM,IAAI,KAAK,mBAAmB,SAAS,OAAO;AAE1E,gBAAI,kBAAkB,MAAM,SAAS,GAAG;AACtC,qBAAO,MAAM,iCAAiC;AAAA,gBAC5C,QAAQA;AAAA,gBACR,QAAQ,OAAO,QAAQ,CAAC;AAAA,gBACxB,WAAW,MAAM;AAAA,gBACjB,OAAO,QAAQ;AAAA,cACjB,CAAC;AAGD,yBAAW,QAAQ,OAAO;AAExB,sBAAM,gBAAgB,eAAe,IAAI,KAAK,UAAU,KAAK;AAC7D,sBAAM,cAAc,gBAAgB,KAAK;AACzC,+BAAe,IAAI,KAAK,YAAY,WAAW;AAG/C,qBAAK,cAAcA,OAAM,KAAK,YAAY,KAAK,MAAM;AACrD,wBAAQ,iBAAiBA,OAAM,KAAK,YAAY,KAAK,MAAM;AAE3D,uBAAO,MAAM,2BAA2B;AAAA,kBACtC,MAAMA;AAAA,kBACN,IAAI,KAAK;AAAA,kBACT,mBAAmB,KAAK,OAAO,QAAQ,CAAC;AAAA,kBACxC,aAAa,YAAY,QAAQ,CAAC;AAAA,gBACpC,CAAC;AAAA,cACH;AAAA,YACF;AAAA,UACF;AAGA,kBAAQ,WAAW,MAAM;AAGzB,qBAAW,CAACA,OAAM,MAAM,KAAK,gBAAgB;AAC3C,oBAAQ,cAAcA,OAAM,MAAM;AAGlC,gBAAI,WAAW,KAAK,mBAAmB,mBAAmB,OAAO;AAC/D,kBAAI,CAAC,QAAQ,YAAYA,KAAI,GAAG;AAC9B,wBAAQ,cAAcA,KAAI;AAC1B,qBAAK,gBAAgBA,OAAM,QAAQ,QAAQ,CAAC;AAAA,cAC9C;AAAA,YACF;AAAA,UACF;AAGA,eAAK,mBAAmB,WAAW,OAAO;AAG1C,kBAAQ,eAAe;AAGvB,cAAI,eAAe,SAAS,GAAG;AAC7B,mBAAO,MAAM,yCAAyC;AAAA,cACpD,OAAO,QAAQ;AAAA,YACjB,CAAC;AACD;AAAA,UACF;AAAA,QACF;AAEA,cAAM,WAAW,KAAK,IAAI,IAAI;AAG9B,aAAK,QAAQ,sBAAsB,QAAQ,cAAc;AAEzD,eAAO,KAAK,6BAA6B;AAAA,UACvC,QAAQ;AAAA,UACR,UAAU,KAAK,mBAAmB;AAAA,UAClC,QAAQ,QAAQ;AAAA,UAChB,gBAAgB,QAAQ,eAAe;AAAA,UACvC,aAAa,QAAQ,YAAY;AAAA,UACjC,UAAU,GAAG,QAAQ;AAAA,QACvB,CAAC;AAED,eAAO;AAAA,MACT;AAAA,IACF;AAEA,IAAAL,QAAO,UAAUC;AAAA;AAAA;;;AC7MjB;AAAA,2BAAAK,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AA6DxC,QAAMC,UAAS;AAEf,QAAMC,SAAN,cAAoBD,QAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWzB,eAAe;AA1EjB;AA2EI,YAAI,KAAK,QAAQ,KAAK,SAAS,GAAG;AAChC,iBAAO,KAAK,4CAA4C;AACxD,iBAAO;AAAA,QACT;AAEA,eAAO,MAAM,+CAA+C;AAAA,UAC1D,WAAW,KAAK,QAAQ,KAAK;AAAA,QAC/B,CAAC;AAGD,cAAM,YAAY,KAAK,cAAc;AACrC,YAAI,UAAU,SAAS,GAAG;AAExB,gBAAM,eAAe,UAAU,OAAO,CAAC,MAAM,YAAY;AAxF/D,gBAAAE,KAAAC,KAAA;AAyFQ,kBAAM,qBAAmBA,OAAAD,MAAA,KAAK,QAAQ,KAAK,IAAI,OAAO,MAA7B,gBAAAA,IAAgC,gBAAhC,gBAAAC,IAA6C,SAAQ;AAC9E,kBAAM,kBAAgB,gBAAK,QAAQ,KAAK,IAAI,IAAI,MAA1B,mBAA6B,gBAA7B,mBAA0C,SAAQ;AACxE,mBAAO,mBAAmB,gBAAgB,UAAU;AAAA,UACtD,CAAC;AAED,iBAAO,KAAK,4CAA4C;AAAA,YACtD,MAAM;AAAA,YACN,UAAU;AAAA,YACV,aAAW,gBAAK,QAAQ,KAAK,IAAI,YAAY,MAAlC,mBAAqC,gBAArC,mBAAkD,SAAQ;AAAA,UACvE,CAAC;AACD,iBAAO;AAAA,QACT;AAGA,cAAM,YAAY,KAAK,QAAQ,mBAAmB;AAClD,YAAI,UAAU,OAAO,GAAG;AACtB,cAAI,YAAY;AAChB,cAAI,YAAY;AAEhB,qBAAW,CAAC,MAAM,MAAM,KAAK,WAAW;AACtC,gBAAI,SAAS,WAAW;AACtB,0BAAY;AACZ,0BAAY;AAAA,YACd;AAAA,UACF;AAEA,cAAI,WAAW;AACb,mBAAO,KAAK,sDAAsD;AAAA,cAChE,MAAM;AAAA,cACN,UAAU;AAAA,YACZ,CAAC;AACD,mBAAO;AAAA,UACT;AAAA,QACF;AAGA,cAAM,YAAY,KAAK,QAAQ,KAAK,KAAK,EAAE,KAAK,EAAE;AAClD,eAAO,MAAM,uCAAuC;AAAA,UAClD,MAAM;AAAA,QACR,CAAC;AACD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,gBAAgB;AACd,cAAM,kBAAkB,oBAAI,IAAI;AAGhC,mBAAW,CAAC,YAAY,SAAS,KAAK,KAAK,QAAQ,MAAM;AACvD,qBAAW,CAAC,UAAU,KAAK,UAAU,aAAa;AAChD,4BAAgB,IAAI,UAAU;AAAA,UAChC;AAAA,QACF;AAGA,cAAM,YAAY,CAAC;AACnB,mBAAW,QAAQ,KAAK,QAAQ,KAAK,KAAK,GAAG;AAC3C,cAAI,CAAC,gBAAgB,IAAI,IAAI,GAAG;AAC9B,sBAAU,KAAK,IAAI;AAAA,UACrB;AAAA,QACF;AAEA,eAAO,MAAM,4BAA4B;AAAA,UACvC,OAAO,UAAU;AAAA,UACjB,OAAO;AAAA,QACT,CAAC;AAED,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,QAAQ,OAAO,MAAM;AAxKvB;AAyKI,eAAO,KAAK,oCAAoC;AAAA,UAC9C,cAAc;AAAA,UACd,YAAY,CAAC;AAAA,UACb,aAAa,KAAK,QAAQ,KAAK;AAAA,QACjC,CAAC;AAGD,YAAI,CAAC,MAAM;AACT,iBAAO,KAAK,aAAa;AACzB,cAAI,CAAC,MAAM;AACT,mBAAO,MAAM,sEAAsE;AACnF,mBAAO;AAAA,UACT;AACA,iBAAO,KAAK,oCAAoC,EAAE,KAAK,CAAC;AAAA,QAC1D,OAAO;AAEL,cAAI,CAAC,KAAK,QAAQ,OAAO,IAAI,GAAG;AAC9B,mBAAO,KAAK,8CAA8C,EAAE,KAAK,CAAC;AAClE,mBAAO;AAAA,UACT;AAAA,QACF;AAEA,eAAO,KAAK,4CAA4C;AAAA,UACtD;AAAA,UACA,WAAW,KAAK,QAAQ,OAAO,IAAI;AAAA,UACnC,kBAAgB,gBAAK,QAAQ,KAAK,IAAI,IAAI,MAA1B,mBAA6B,gBAA7B,mBAA0C,SAAQ;AAAA,QACpE,CAAC;AAGD,cAAM,OAAO,MAAM,QAAQ,IAAI;AAE/B,YAAI,MAAM;AACR,iBAAO,KAAK,wCAAwC;AAAA,YAClD,WAAW;AAAA,YACX,gBAAgB,KAAK,cAAc;AAAA,YACnC,aAAa,KAAK,YAAY;AAAA,UAChC,CAAC;AAAA,QACH,OAAO;AACL,iBAAO,MAAM,wBAAwB,EAAE,KAAK,CAAC;AAAA,QAC/C;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWA,gBAAgB,OAAO;AACrB,eAAO,KAAK,uCAAuC;AAAA,UACjD;AAAA,UACA,OAAO,MAAM;AAAA,QACf,CAAC;AAED,cAAMC,QAAO;AAGb,cAAM,aAAa,IAAIA,MAAK,IAAI;AAChC,mBAAW,UAAU,CAAC;AAEtB,cAAM,eAAe,CAAC;AACtB,cAAM,eAAe,CAAC;AAGtB,mBAAW,QAAQ,OAAO;AACxB,gBAAM,MAAM,KAAK,QAAQ,KAAK,IAAI,IAAI;AACtC,cAAI,CAAC,KAAK;AACR,yBAAa,KAAK,IAAI;AACtB,mBAAO,KAAK,qCAAqC,EAAE,KAAK,CAAC;AACzD;AAAA,UACF;AAEA,uBAAa,KAAK,IAAI;AACtB,qBAAW,QAAQ,KAAK,GAAG;AAE3B,iBAAO,MAAM,iCAAiC;AAAA,YAC5C;AAAA,YACA,WAAW,IAAI,YAAY;AAAA,UAC7B,CAAC;AAGD,eAAK,OAAO,KAAK,YAAY,CAAC,GAAG,CAAC;AAAA,QACpC;AAEA,eAAO,KAAK,wCAAwC;AAAA,UAClD,gBAAgB,MAAM;AAAA,UACtB,cAAc,aAAa;AAAA,UAC3B;AAAA,UACA,gBAAgB,WAAW,cAAc;AAAA,UACzC,aAAa,WAAW,YAAY;AAAA,QACtC,CAAC;AAED,eAAO;AAAA,MACT;AAAA,IACF;AAEA,IAAAL,QAAO,UAAUE;AAAA;AAAA;;;AC9QjB;AAAA,4BAAAI,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,EAAE,MAAM,IAAI,QAAQ,OAAO;AACjC,QAAM,SAAS,QAAQ,iBAAiB;AAyBxC,QAAM,SAAN,MAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAMX,YAAY,QAAQ;AAKlB,aAAK,KAAK,IAAI,MAAM,QAAQ;AAAA,UAC1B,eAAe;AAAA;AAAA,QACjB,CAAC;AAED,eAAO,MAAM,wBAAwB,EAAE,OAAO,CAAC;AAAA,MACjD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,MAAM,MAAM,QAAQ;AAElB,cAAM,MAAM,OAAO;AAEnB,YAAI;AACF,gBAAM,KAAK,GAAG,IAAI,KAAK,OAAO,OAAO,CAAC;AAEtC,iBAAO,MAAM,0BAA0B;AAAA,YACrC;AAAA,YACA,SAAS,OAAO,WAAW;AAAA,YAC3B,UAAU,OAAO;AAAA,UACnB,CAAC;AAED,iBAAO;AAAA,QACT,SAAS,OAAO;AACd,iBAAO,MAAM,mCAAmC;AAAA,YAC9C;AAAA,YACA,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,MAAM,IAAI,KAAK;AACb,YAAI;AACF,gBAAM,OAAO,MAAM,KAAK,GAAG,IAAI,GAAG;AAElC,iBAAO,MAAM,6BAA6B;AAAA,YACxC;AAAA,YACA,YAAY,CAAC,CAAC,KAAK;AAAA,UACrB,CAAC;AAED,iBAAO;AAAA,QACT,SAAS,OAAO;AACd,cAAI,MAAM,UAAU;AAClB,mBAAO,MAAM,6BAA6B,EAAE,IAAI,CAAC;AACjD,mBAAO;AAAA,UACT;AAEA,iBAAO,MAAM,sCAAsC;AAAA,YACjD;AAAA,YACA,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,QAAQ;AACZ,YAAI;AACF,gBAAM,KAAK,GAAG,MAAM;AACpB,iBAAO,MAAM,0BAA0B;AAAA,QACzC,SAAS,OAAO;AACd,iBAAO,MAAM,qCAAqC;AAAA,YAChD,OAAO,MAAM;AAAA,UACf,CAAC;AACD,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,gBAAgB;AACpB,YAAI;AACF,cAAI,QAAQ;AACZ,2BAAiB,CAAC,GAAG,KAAK,KAAK,GAAG,SAAS,GAAG;AAC5C;AAAA,UACF;AAEA,iBAAO;AAAA,YACL,cAAc;AAAA,YACd,QAAQ,KAAK,GAAG;AAAA,UAClB;AAAA,QACF,SAAS,OAAO;AACd,iBAAO,MAAM,qCAAqC;AAAA,YAChD,OAAO,MAAM;AAAA,UACf,CAAC;AACD,iBAAO;AAAA,YACL,cAAc;AAAA,YACd,QAAQ,KAAK,GAAG;AAAA,YAChB,OAAO,MAAM;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAAA,QAAO,UAAU;AAAA;AAAA;;;ACrJjB;AAAA,oCAAAC,UAAAC,SAAA;AAAA;AAAA;AAqCA,QAAMC,kBAAN,MAAqB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAcnB,UAAU,SAAS;AACjB,cAAM,IAAI,MAAM,gDAAgD;AAAA,MAClE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWA,uBAAuB,OAAO;AAC5B,YAAI,MAAM,WAAW,EAAG,QAAO;AAG/B,cAAM,cAAc,MAAM,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,QAAQ,CAAC;AAC9D,eAAO,MAAM,IAAI,WAAS;AAAA,UACxB,GAAG;AAAA,UACH,aAAa,KAAK,SAAS;AAAA,QAC7B,EAAE;AAAA,MACJ;AAAA,IACF;AA0BA,QAAMC,wBAAN,cAAmCD,gBAAe;AAAA,MAChD,YAAY,UAAU,CAAC,GAAG;AACxB,cAAM;AAMN,aAAK,aAAa,QAAQ,cAAc;AAMxC,aAAK,QAAQ,QAAQ,SAAS;AAAA,MAChC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,UAAU,SAAS;AAEjB,cAAM,SAAS,KAAK,aAAa,KAAK,IAAI,KAAK,OAAO,QAAQ,QAAQ;AACtE,eAAO;AAAA,MACT;AAAA,IACF;AAqEA,QAAME,2BAAN,cAAsCF,gBAAe;AAAA,MACnD,YAAY,UAAU,CAAC,GAAG;AACxB,cAAM;AAON,aAAK,QAAQ,QAAQ,SAAS;AAO9B,aAAK,sBAAsB,QAAQ,uBAAuB;AAO1D,aAAK,kBAAkB,QAAQ,mBAAmB;AAOlD,aAAK,UAAU;AAAA,MACjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,UAAU,SAAS;AAEjB,cAAM,YAAY,QAAQ;AAG1B,cAAM,iBAAiB,KAAK,IAAI,KAAK,OAAO,QAAQ,QAAQ;AAG5D,cAAM,iBAAiB,QAAQ,YAAY;AAG3C,cAAM,SAAS,YAAY,iBAAiB;AAE5C,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,uBAAuB,OAAO;AAC5B,YAAI,MAAM,WAAW,EAAG,QAAO;AAG/B,cAAM,gBAAgB,MAAM,IAAI,UAAQ;AAEtC,cAAI,YAAY;AAChB,cAAI,KAAK,SAAS;AAChB,kBAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,KAAK,UAAU;AACvD,wBAAY,YAAa,UAAU,mBAAmB,IAAK;AAAA,UAC7D;AAGA,gBAAM,YAAY,KAAK,IAAI,KAAK,MAAM;AACtC,gBAAM,gBAAgB,KAAK,IAAI,IAAI,YAAY,KAAK,eAAe;AAEnE,iBAAO;AAAA,YACL,GAAG;AAAA,YACH,mBAAmB,YAAY;AAAA,YAC/B;AAAA,UACF;AAAA,QACF,CAAC;AAGD,cAAM,eAAe,KAAK,IAAI,GAAG,cAAc,IAAI,OAAK,EAAE,iBAAiB,CAAC;AAG5E,cAAM,aAAa,cAAc;AAAA,UAAI,OACnC,KAAK,IAAI,EAAE,oBAAoB,YAAY;AAAA,QAC7C;AACA,cAAM,SAAS,WAAW,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAGnD,cAAM,kBAAkB,MAAM,IAAI,CAAC,MAAM,OAAO;AAAA,UAC9C,GAAG;AAAA,UACH,aAAa,WAAW,CAAC,IAAI;AAAA,UAC7B,WAAW,cAAc,CAAC,EAAE;AAAA,QAC9B,EAAE,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,cAAc,EAAE,WAAW;AAGhD,eAAO,gBAAgB,OAAO,UAAQ,KAAK,eAAe,KAAK,mBAAmB;AAAA,MACpF;AAAA,IACF;AAmCA,QAAM,4BAAN,cAAwCE,yBAAwB;AAAA,MAC9D,YAAY,UAAU,CAAC,GAAG;AACxB,cAAM,OAAO;AAOb,aAAK,cAAc,QAAQ,eAAe;AAO1C,aAAK,eAAe,QAAQ,gBAAgB;AAAA,MAC9C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,iBAAiB,OAAO;AACtB,cAAM,cAAc;AAAA,UAClB,OAAO;AAAA;AAAA,UACP,UAAU;AAAA;AAAA,UACV,QAAQ;AAAA;AAAA,QACV;AAEA,aAAK,cAAc,YAAY,KAAK,KAAK;AACzC,aAAK,eAAe;AAAA,MACtB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,sBAAsB,YAAY;AAEhC,cAAM,oBAAoB,KAAK,IAAI,GAAG,KAAK,IAAI,KAAK,UAAU,CAAC;AAC/D,aAAK,cAAc,IAAO,oBAAoB,MAAO;AACrD,aAAK,eAAe;AAAA,MACtB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,sBAAsB,OAAO;AAC3B,YAAI,KAAK,iBAAiB,QAAQ;AAChC,iBAAO,KAAK;AAAA,QACd;AAGA,cAAM,iBAAiB,MAAM;AAC7B,cAAM,eAAe;AAErB,YAAI,iBAAiB,eAAe,GAAG;AAErC,iBAAO;AAAA,QACT,WAAW,iBAAiB,cAAc;AAExC,iBAAO;AAAA,QACT,OAAO;AAEL,iBAAO;AAAA,QACT;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAaA,uBAAuB,OAAO;AAC5B,YAAI,MAAM,WAAW,EAAG,QAAO;AAG/B,cAAM,uBAAuB,KAAK,sBAAsB,KAAK;AAG7D,cAAM,gBAAgB,MAAM,IAAI,UAAQ;AAEtC,cAAI,YAAY;AAChB,cAAI,KAAK,SAAS;AAChB,kBAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,KAAK,UAAU;AACvD,wBAAY,YAAa,UAAU,mBAAmB,IAAK;AAAA,UAC7D;AAGA,gBAAM,YAAY,KAAK,IAAI,KAAK,MAAM;AACtC,gBAAM,gBAAgB,KAAK,IAAI,IAAI,YAAY,KAAK,eAAe;AAEnE,iBAAO;AAAA,YACL,GAAG;AAAA,YACH,mBAAmB,YAAY;AAAA,YAC/B;AAAA,UACF;AAAA,QACF,CAAC;AAGD,cAAM,eAAe,KAAK,IAAI,GAAG,cAAc,IAAI,OAAK,EAAE,iBAAiB,CAAC;AAK5E,cAAM,aAAa,cAAc;AAAA,UAAI,OACnC,KAAK,KAAK,EAAE,oBAAoB,gBAAgB,oBAAoB;AAAA,QACtE;AACA,cAAM,SAAS,WAAW,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAGnD,cAAM,kBAAkB,cAAc,IAAI,CAAC,MAAM,OAAO;AAAA,UACtD,GAAG,MAAM,CAAC;AAAA,UACV,aAAa,WAAW,CAAC,IAAI;AAAA,UAC7B,WAAW,KAAK;AAAA,UAChB,aAAa;AAAA,QACf,EAAE,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,cAAc,EAAE,WAAW;AAGhD,eAAO,gBAAgB,OAAO,UAAQ,KAAK,eAAe,KAAK,mBAAmB;AAAA,MACpF;AAAA,IAEF;AAEA,IAAAH,QAAO,UAAU;AAAA,MACf,gBAAAC;AAAA,MACA,sBAAAC;AAAA,MACA,yBAAAC;AAAA,MACA;AAAA,IACF;AAAA;AAAA;;;AC/dA;AAAA,qCAAAC,UAAAC,SAAA;AAAA;AAAA;AAAA,QAAM,SAAS,QAAQ,iBAAiB;AACxC,QAAMC,WAAU;AAChB,QAAMC,YAAW;AACjB,QAAMC,UAAS;AACf,QAAMC,SAAQ;AACd,QAAM,SAAS;AACf,QAAM,EAAE,0BAA0B,IAAI;AAyCtC,QAAMC,mBAAN,MAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUpB,YAAY,UAAU,CAAC,GAAG;AAKxB,aAAK,WAAW,QAAQ,YAAY;AAMpC,aAAK,UAAU,IAAIJ,SAAQ;AAM3B,aAAK,WAAW,IAAI,0BAA0B;AAAA,UAC5C,OAAO;AAAA,UACP,qBAAqB;AAAA;AAAA,UACrB,iBAAiB;AAAA;AAAA,UACjB,aAAa;AAAA;AAAA,UACb,cAAc;AAAA;AAAA,UACd,GAAG,QAAQ;AAAA,QACb,CAAC;AAGD,aAAK,SAAS,UAAU,KAAK;AAM7B,aAAK,kBAAkB;AAAA,UACrB,GAAG,QAAQ;AAAA,UACX,UAAU,KAAK;AAAA,QACjB;AAMA,aAAK,gBAAgB;AAAA,UACnB,GAAG,QAAQ;AAAA,UACX,gBAAgB,KAAK;AAAA;AAAA,QACvB;AAMA,aAAK,iBAAiB;AAMtB,aAAK,eAAe;AAMpB,aAAK,SAAS;AAEd,eAAO,KAAK,iCAAiC;AAAA,UAC3C,UAAU,KAAK;AAAA,UACf,cAAc,KAAK,SAAS,YAAY;AAAA,QAC1C,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,oBAAoB;AAClB,YAAI,CAAC,KAAK,gBAAgB;AACxB,eAAK,iBAAiB,IAAIC,UAAS,KAAK,SAAS,KAAK,eAAe;AAAA,QACvE;AACA,eAAO,KAAK;AAAA,MACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,kBAAkB;AAChB,YAAI,CAAC,KAAK,cAAc;AACtB,eAAK,eAAe,IAAIC,QAAO,KAAK,SAAS,KAAK,aAAa;AAAA,QACjE;AACA,eAAO,KAAK;AAAA,MACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,YAAY;AACV,YAAI,CAAC,KAAK,UAAU,KAAK,QAAQ,WAAW;AAC1C,gBAAM,OAAO,QAAQ,MAAM;AAC3B,gBAAM,aAAa,KAAK,KAAK,KAAK,QAAQ,WAAW,YAAY;AACjE,eAAK,SAAS,IAAI,OAAO,UAAU;AAAA,QACrC;AACA,eAAO,KAAK;AAAA,MACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAaA,MAAM,SAAS,QAAQ;AACrB,eAAO,MAAM,wCAAwC;AAAA,UACnD,IAAI,OAAO;AAAA,UACX,cAAc,OAAO;AAAA,UACrB,UAAU,OAAO;AAAA,UACjB,SAAS,OAAO,WAAW;AAAA,QAC7B,CAAC;AAGD,YAAI,KAAK,UAAU,GAAG;AACpB,cAAI;AACF,kBAAM,KAAK,UAAU,EAAE,MAAM,MAAM;AACnC,mBAAO,MAAM,6CAA6C,EAAE,IAAI,OAAO,GAAG,CAAC;AAAA,UAC7E,SAAS,OAAO;AACd,mBAAO,MAAM,sDAAsD;AAAA,cACjE,IAAI,OAAO;AAAA,cACX,OAAO,MAAM;AAAA,YACf,CAAC;AACD,kBAAM;AAAA,UACR;AAAA,QACF;AAEA,cAAM,WAAW,KAAK,kBAAkB;AACxC,cAAM,SAAS,SAAS,QAAQ,QAAQ,OAAO,EAAE;AAKjD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAcA,MAAM,OAAO,MAAM;AACjB,eAAO,MAAM,sCAAsC,EAAE,KAAK,CAAC;AAE3D,cAAM,SAAS,KAAK,gBAAgB;AACpC,cAAM,OAAO,OAAO,QAAQ,IAAI;AAEhC,YAAI,CAAC,MAAM;AACT,iBAAO;AAAA,QACT;AAGA,YAAI,KAAK,UAAU,GAAG;AACpB,cAAI;AACF,kBAAM,KAAK,YAAY,MAAM,IAAI;AAAA,UACnC,SAAS,OAAO;AACd,mBAAO,MAAM,4CAA4C,EAAE,OAAO,MAAM,QAAQ,CAAC;AAAA,UAEnF;AAAA,QACF;AAGA,YAAI,KAAK,cAAc,OAAO,GAAG;AAC/B,eAAK,QAAQ,sBAAsB,KAAK,aAAa;AACrD,iBAAO,MAAM,sDAAsD;AAAA,YACjE,gBAAgB,KAAK,cAAc;AAAA,UACrC,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,MAAM,YAAY,MAAM,eAAe;AAlQzC;AAmQI,aAAK,UAAU,CAAC;AAGhB,eAAO,KAAK,kDAAkD;AAAA,UAC5D;AAAA,UACA,iBAAiB,KAAK,QAAQ,KAAK;AAAA,UACnC,iBAAiB,CAAC,CAAC,KAAK,UAAU;AAAA,UAClC,iBAAiB,MAAM,KAAK,KAAK,QAAQ,KAAK,KAAK,CAAC;AAAA,QACtD,CAAC;AAGD,cAAM,WAAW,KAAK,QAAQ,KAAK,IAAI,aAAa;AAEpD,eAAO,KAAK,8CAA8C;AAAA,UACxD;AAAA,UACA,aAAa,CAAC,CAAC;AAAA,UACf,kBAAkB,qCAAU;AAAA,UAC5B,iBAAgB,0CAAU,aAAV,mBAAoB;AAAA,QACtC,CAAC;AAED,YAAI,YAAY,SAAS,UAAU;AACjC,qBAAW,YAAY,SAAS,UAAU;AACxC,kBAAM,aAAa,MAAM,KAAK,UAAU,EAAE,IAAI,QAAQ;AAEtD,mBAAO,MAAM,6CAA6C;AAAA,cACxD;AAAA,cACA,eAAe,CAAC,CAAC;AAAA,cACjB,gBAAe,8CAAY,YAAZ,mBAAqB,UAAU,GAAG;AAAA,YACnD,CAAC;AAED,gBAAI,YAAY;AACd,mBAAK,QAAQ,KAAK;AAAA,gBAChB,IAAI,WAAW;AAAA,gBACf,SAAS,WAAW;AAAA,gBACpB,QAAQ,WAAW;AAAA,gBACnB,UAAU,WAAW;AAAA,gBACrB,WAAW,WAAW;AAAA,gBACtB,aAAa;AAAA,cACf,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF,OAAO;AACL,iBAAO,KAAK,yDAAyD;AAAA,YACnE,aAAa,CAAC,CAAC;AAAA,YACf,aAAa,CAAC,EAAC,qCAAU;AAAA,YACzB,OAAO;AAAA,UACT,CAAC;AAAA,QACH;AAEA,eAAO,MAAM,oCAAoC;AAAA,UAC/C,OAAO;AAAA,UACP,aAAa,KAAK,QAAQ;AAAA,QAC5B,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYA,MAAM,QAAQ;AApUhB;AAqUI,eAAO,MAAM,mCAAmC;AAIhD,eAAO,KAAK,4CAA4C;AAAA,UACtD,MAAM,KAAK,QAAQ,KAAK;AAAA,QAC1B,CAAC;AAGD,cAAM,QAAQ,IAAIC,OAAM,KAAK,OAAO;AACpC,cAAM,OAAO,MAAM,QAAQ;AAE3B,YAAI,CAAC,MAAM;AACT,iBAAO,KAAK,2EAA2E;AACvF,iBAAO;AAAA,QACT;AAEA,eAAO,KAAK,qCAAqC;AAAA,UAC/C,kBAAgB,UAAK,kBAAL,mBAAoB,SAAQ;AAAA,UAC5C,eAAa,UAAK,gBAAL,mBAAkB,WAAU;AAAA,UACzC,YAAY,KAAK;AAAA,QACnB,CAAC;AAGD,YAAI,KAAK,UAAU,KAAK,KAAK,YAAY;AACvC,cAAI;AACF,kBAAM,KAAK,YAAY,MAAM,KAAK,UAAU;AAC5C,mBAAO,KAAK,0DAA0D;AAAA,cACpE,YAAY,KAAK;AAAA,cACjB,eAAa,UAAK,YAAL,mBAAc,WAAU;AAAA,YACvC,CAAC;AAAA,UACH,SAAS,OAAO;AACd,mBAAO,MAAM,sDAAsD;AAAA,cACjE,YAAY,KAAK;AAAA,cACjB,OAAO,MAAM;AAAA,YACf,CAAC;AAAA,UAEH;AAAA,QACF;AAIA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,gBAAgB;AACd,cAAM,eAAe,KAAK,QAAQ,cAAc;AAChD,cAAM,iBAAiB,KAAK,QAAQ,uBAAuB;AAE3D,eAAO;AAAA,UACL,SAAS;AAAA,UACT,WAAW;AAAA,UACX,UAAU,KAAK;AAAA,UACf,UAAU;AAAA,YACR,MAAM,KAAK,SAAS,YAAY;AAAA,YAChC,OAAO,KAAK,SAAS;AAAA,YACrB,iBAAiB,KAAK,SAAS,mBAAmB;AAAA,UACpD;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,QAAQ;AACN,aAAK,QAAQ,MAAM;AACnB,aAAK,iBAAiB;AACtB,aAAK,eAAe;AACpB,eAAO,KAAK,kCAAkC;AAAA,MAChD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,OAAO;AACL,aAAK,QAAQ,YAAY,KAAK,QAAQ;AACtC,eAAO,KAAK,yCAAyC;AAAA,MACvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,OAAO;AACL,aAAK,QAAQ,SAAS,KAAK,QAAQ;AAEnC,aAAK,iBAAiB;AACtB,aAAK,eAAe;AACpB,eAAO,KAAK,yCAAyC;AAAA,MACvD;AAAA,IACF;AAEA,IAAAJ,QAAO,UAAUK;AAAA;AAAA;;;AC3ajB;AAcA,IAAM,MAAM;AACZ,IAAM,UAAU;AAChB,IAAM,OAAO;AACb,IAAM,WAAW;AACjB,IAAM,SAAS;AACf,IAAM,QAAQ;AACd,IAAM,gBAAgB;AACtB,IAAM,oBAAoB;AAC1B,IAAM,kBAAkB;AACxB,IAAM,EAAE,gBAAgB,sBAAsB,wBAAwB,IAAI;AAC1E,IAAM,EAAE,oBAAoB,8BAA8B,IAAI;AAE9D,OAAO,UAAU;AAAA;AAAA,EAEf;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA;AAAA,EAGA;AACF;","names":["exports","module","Cue","exports","module","Cue","exports","module","Network","fs","path","exports","module","Mind","exports","module","exports","module","WeightContext","exports","module","Remember","WeightContext","exports","module","ActivationStrategy","HippocampalActivationStrategy","exports","module","ActivationContext","exports","module","Recall","HippocampalActivationStrategy","Mind","ActivationContext","word","exports","module","Recall","Prime","_a","_b","Mind","exports","module","exports","module","WeightStrategy","SimpleWeightStrategy","TimeBasedWeightStrategy","exports","module","Network","Remember","Recall","Prime","CognitionSystem"]}